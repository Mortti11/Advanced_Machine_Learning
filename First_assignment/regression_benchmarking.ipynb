{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns  \n",
    "import time\n",
    " \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import keras_tuner\n",
    "from keras import regularizers\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset  \n",
    "df = pd.read_csv('dataset_regression/parkinsons_updrs_cleaned.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "motor_UPDRS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HNR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RPDE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DFA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PPE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Jitter_combined",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Shimmer_combined",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6822eebc-bd32-4619-9bed-d24792c1c811",
       "rows": [
        [
         "0",
         "72",
         "28.447",
         "20.533",
         "0.55096",
         "0.55348",
         "0.26094",
         "0.0064",
         "0.0927"
        ],
        [
         "1",
         "72",
         "30.917",
         "21.571",
         "0.56359",
         "0.5566",
         "0.27912",
         "0.0055",
         "0.0638"
        ],
        [
         "2",
         "72",
         "29.682",
         "25.347",
         "0.43478",
         "0.5514",
         "0.26728",
         "0.0058",
         "0.0462"
        ],
        [
         "3",
         "58",
         "11.078",
         "20.632",
         "0.541",
         "0.75905",
         "0.19288",
         "0.0042",
         "0.0841"
        ],
        [
         "4",
         "58",
         "11.218",
         "18.254",
         "0.48799",
         "0.76679",
         "0.22277",
         "0.0059",
         "0.1041"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>motor_UPDRS</th>\n",
       "      <th>HNR</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>PPE</th>\n",
       "      <th>Jitter_combined</th>\n",
       "      <th>Shimmer_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>28.447</td>\n",
       "      <td>20.533</td>\n",
       "      <td>0.55096</td>\n",
       "      <td>0.55348</td>\n",
       "      <td>0.26094</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>30.917</td>\n",
       "      <td>21.571</td>\n",
       "      <td>0.56359</td>\n",
       "      <td>0.55660</td>\n",
       "      <td>0.27912</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>29.682</td>\n",
       "      <td>25.347</td>\n",
       "      <td>0.43478</td>\n",
       "      <td>0.55140</td>\n",
       "      <td>0.26728</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>11.078</td>\n",
       "      <td>20.632</td>\n",
       "      <td>0.54100</td>\n",
       "      <td>0.75905</td>\n",
       "      <td>0.19288</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>11.218</td>\n",
       "      <td>18.254</td>\n",
       "      <td>0.48799</td>\n",
       "      <td>0.76679</td>\n",
       "      <td>0.22277</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.1041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  motor_UPDRS     HNR     RPDE      DFA      PPE  Jitter_combined  \\\n",
       "0   72       28.447  20.533  0.55096  0.55348  0.26094           0.0064   \n",
       "1   72       30.917  21.571  0.56359  0.55660  0.27912           0.0055   \n",
       "2   72       29.682  25.347  0.43478  0.55140  0.26728           0.0058   \n",
       "3   58       11.078  20.632  0.54100  0.75905  0.19288           0.0042   \n",
       "4   58       11.218  18.254  0.48799  0.76679  0.22277           0.0059   \n",
       "\n",
       "   Shimmer_combined  \n",
       "0            0.0927  \n",
       "1            0.0638  \n",
       "2            0.0462  \n",
       "3            0.0841  \n",
       "4            0.1041  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2296, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am gonna choose the motor_UPDRS as the target  variable\n",
    "X = df.drop(['motor_UPDRS'], axis=1)\n",
    "y = df['motor_UPDRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train, validation and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    2296.000000\n",
       "mean       18.923689\n",
       "std         6.867635\n",
       "min         5.037700\n",
       "25%        13.677500\n",
       "50%        18.000000\n",
       "75%        24.140000\n",
       "max        37.364000\n",
       "Name: motor_UPDRS, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Overall distribution:\")\n",
    "df['motor_UPDRS'].describe()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1836.000000\n",
       "mean       18.941759\n",
       "std         6.888827\n",
       "min         5.037700\n",
       "25%        13.691000\n",
       "50%        18.000000\n",
       "75%        24.110000\n",
       "max        37.364000\n",
       "Name: motor_UPDRS, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nTraining set distribution:\")\n",
    "y_train.describe()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    230.000000\n",
       "mean      18.813099\n",
       "std        6.871624\n",
       "min        5.437100\n",
       "25%       13.589500\n",
       "50%       17.936500\n",
       "75%       24.182000\n",
       "max       36.567000\n",
       "Name: motor_UPDRS, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nTest set distribution:\")\n",
    "y_test.describe()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of X_train: (1836, 7)\n",
      "\n",
      "Shape of X_test: (230, 7)\n",
      "\n",
      "Shape of y_train: (1836,)\n",
      "\n",
      "Shape of y_test: (230,)\n",
      "\n",
      "Shape of X_val: (230, 7)\n",
      "\n",
      "Shape of y_val: (230,)\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nShape of X_train: {X_train.shape}')\n",
    "print(f'\\nShape of X_test: {X_test.shape}')\n",
    "print(f'\\nShape of y_train: {y_train.shape}')\n",
    "print(f'\\nShape of y_test: {y_test.shape}')\n",
    "print(f'\\nShape of X_val: {X_val.shape}')\n",
    "print(f'\\nShape of y_val: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2296, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 23s]\n",
      "val_loss: 12.85354487101237\n",
      "\n",
      "Best val_loss So Far: 10.944008827209473\n",
      "Total elapsed time: 00h 08m 16s\n"
     ]
    }
   ],
   "source": [
    "# Creating a function to fine tune and adding hp object\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Adding the input layer\n",
    "    model.add(keras.layers.BatchNormalization(\n",
    "        momentum=hp.Float('bn_momentum', 0.1, 0.9, 0.1), input_shape=(len(X.columns),))),\n",
    "  \n",
    "     \n",
    "    \n",
    "    # First Hidden Layer \n",
    "    model.add(keras.layers.Dense(\n",
    "        units=hp.Int('units', min_value=8, max_value=64, step=2),\n",
    "        # For fine tuning the model, I am gonna use tow activation functions relu and tanh\n",
    "        activation=hp.Choice('activation', ['relu', \"tanh\"]),\n",
    "        kernel_regularizer=keras.regularizers.l1(l1=hp.Float('l1', 0, 0.1, step=0.01),)\n",
    "    ))\n",
    "        \n",
    "    # Dropout layer\n",
    "    if hp.Boolean('dropout'):\n",
    "        model.add(keras.layers.Dropout(rate=hp.Float('dropout_rate', 0.1, 0.5, step=0.1)))\n",
    "        \n",
    "        \n",
    "    # Adding additional hidden layers\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 2)):\n",
    "        units = hp.Int(f\"units_{i+1}\", 8, 64, 2)\n",
    "        activation = hp.Choice(f\"activation_{i}\", ['relu', 'tanh', 'LeakyReLU'])\n",
    "       \n",
    "        if activation == 'LeakyReLU':\n",
    "           model.add(keras.layers.Dense(units))\n",
    "           model.add(keras.layers.LeakyReLU(negative_slope=hp.Float('leaky_relu_slope', 0.1, 0.5, step=0.1)))\n",
    "            \n",
    "        else:\n",
    "           model.add(keras.layers.Dense(units, activation=activation))\n",
    "           \n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    # Setting up the optimizer and compiling the model \n",
    "    learning_rate = hp.Float('lr', min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    # Creating the dictionary for the optimizers for givin flexibility to the model\n",
    "    optimizers = {\n",
    "        'adam': keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        'sgd': keras.optimizers.SGD(learning_rate=learning_rate, momentum=hp.Float('momentum', 0.0, 0.9, 0.1)),\n",
    "        'rmsprop': keras.optimizers.RMSprop(learning_rate=learning_rate)}[hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])]\n",
    "    \n",
    "    model.compile(optimizer=optimizers, loss='mse',metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())  \n",
    "\n",
    "# Setting up the Keras tuner\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model, \n",
    "    objective=\"val_loss\",\n",
    "    #I will got for 10 trials\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    overwrite=True, \n",
    "    directory='dataset_regression/model_tuning',\n",
    "    project_name=\"regression_model\",\n",
    ")\n",
    "\n",
    "mc = ModelCheckpoint('best_model_regression.keras', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "callback = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5),\n",
    "    mc\n",
    "]\n",
    "# Starting searching\n",
    "tuner.search(X_train_scaled, y_train, epochs=250, validation_data=(X_val_scaled, y_val), callbacks=callback)   \n",
    "\n",
    "  \n",
    "# got main idea code from Deep Learning Lecture  notes and modified it for my own dataset and I used https://keras.io/api/models/model/\n",
    "# For debugging I used LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\murta\\Desktop\\Desktop\\ML&DE\\Fourth_Semester\\Advanced_ML\\.venv\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\murta\\Desktop\\Desktop\\ML&DE\\Fourth_Semester\\Advanced_ML\\.venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">336</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m28\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │           \u001b[38;5;34m336\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,009</span> (3.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,009\u001b[0m (3.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">995</span> (3.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m995\u001b[0m (3.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> (56.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14\u001b[0m (56.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in dataset_regression/model_tuning\\regression_model\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.6\n",
      "units: 42\n",
      "activation: tanh\n",
      "l1: 0.01\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 8\n",
      "activation_0: tanh\n",
      "lr: 0.0001787125964217817\n",
      "momentum: 0.0\n",
      "optimizer: sgd\n",
      "units_2: 30\n",
      "activation_1: LeakyReLU\n",
      "dropout_rate: 0.5\n",
      "Score: 10.944008827209473\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.8\n",
      "units: 40\n",
      "activation: tanh\n",
      "l1: 0.0\n",
      "dropout: True\n",
      "num_layers: 1\n",
      "units_1: 4\n",
      "activation_0: LeakyReLU\n",
      "lr: 0.0011055415225593402\n",
      "momentum: 0.0\n",
      "optimizer: rmsprop\n",
      "units_2: 18\n",
      "activation_1: relu\n",
      "dropout_rate: 0.1\n",
      "Score: 10.965479850769043\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.30000000000000004\n",
      "units: 24\n",
      "activation: tanh\n",
      "l1: 0.05\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 6\n",
      "activation_0: relu\n",
      "lr: 0.006320810242350413\n",
      "momentum: 0.4\n",
      "optimizer: rmsprop\n",
      "units_2: 18\n",
      "activation_1: relu\n",
      "dropout_rate: 0.5\n",
      "Score: 11.322022438049316\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.1\n",
      "units: 16\n",
      "activation: tanh\n",
      "l1: 0.04\n",
      "dropout: True\n",
      "num_layers: 1\n",
      "units_1: 22\n",
      "activation_0: LeakyReLU\n",
      "lr: 0.0019764153787523\n",
      "momentum: 0.30000000000000004\n",
      "optimizer: sgd\n",
      "units_2: 8\n",
      "activation_1: tanh\n",
      "dropout_rate: 0.2\n",
      "Score: 11.534472147623697\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.4\n",
      "units: 16\n",
      "activation: relu\n",
      "l1: 0.04\n",
      "dropout: True\n",
      "num_layers: 1\n",
      "units_1: 24\n",
      "activation_0: relu\n",
      "lr: 0.006793126018218034\n",
      "momentum: 0.4\n",
      "optimizer: adam\n",
      "units_2: 6\n",
      "activation_1: relu\n",
      "dropout_rate: 0.2\n",
      "Score: 11.701963742574057\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.2\n",
      "units: 14\n",
      "activation: relu\n",
      "l1: 0.03\n",
      "dropout: False\n",
      "num_layers: 1\n",
      "units_1: 18\n",
      "activation_0: LeakyReLU\n",
      "lr: 0.0023919060853144648\n",
      "momentum: 0.4\n",
      "optimizer: adam\n",
      "units_2: 16\n",
      "activation_1: LeakyReLU\n",
      "Score: 12.441057523091635\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.2\n",
      "units: 26\n",
      "activation: tanh\n",
      "l1: 0.03\n",
      "dropout: True\n",
      "num_layers: 1\n",
      "units_1: 8\n",
      "activation_0: LeakyReLU\n",
      "lr: 0.00401517670583821\n",
      "momentum: 0.4\n",
      "optimizer: rmsprop\n",
      "units_2: 32\n",
      "activation_1: tanh\n",
      "dropout_rate: 0.5\n",
      "Score: 12.85354487101237\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.1\n",
      "units: 18\n",
      "activation: relu\n",
      "l1: 0.0\n",
      "dropout: False\n",
      "num_layers: 2\n",
      "units_1: 30\n",
      "activation_0: relu\n",
      "lr: 0.00028573775765422624\n",
      "momentum: 0.4\n",
      "optimizer: rmsprop\n",
      "units_2: 30\n",
      "activation_1: LeakyReLU\n",
      "Score: 15.259182612101236\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.5\n",
      "units: 46\n",
      "activation: tanh\n",
      "l1: 0.0\n",
      "dropout: False\n",
      "num_layers: 1\n",
      "units_1: 22\n",
      "activation_0: tanh\n",
      "lr: 0.00010665756396599944\n",
      "momentum: 0.6000000000000001\n",
      "optimizer: rmsprop\n",
      "units_2: 26\n",
      "activation_1: relu\n",
      "Score: 16.12414264678955\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.4\n",
      "units: 42\n",
      "activation: relu\n",
      "l1: 0.04\n",
      "dropout: False\n",
      "num_layers: 2\n",
      "units_1: 10\n",
      "activation_0: LeakyReLU\n",
      "lr: 0.004054798565061746\n",
      "momentum: 0.0\n",
      "optimizer: adam\n",
      "units_2: 4\n",
      "activation_1: relu\n",
      "Score: 22.991161346435547\n"
     ]
    }
   ],
   "source": [
    "# Printing  out the results\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Hyperparameter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Value",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e1b48aea-2d4a-4227-a5ce-9cd7e5e88407",
       "rows": [
        [
         "0",
         "bn_momentum",
         "0.6"
        ],
        [
         "1",
         "units",
         "42"
        ],
        [
         "2",
         "activation",
         "tanh"
        ],
        [
         "3",
         "l1",
         "0.01"
        ],
        [
         "4",
         "dropout",
         "True"
        ],
        [
         "5",
         "num_layers",
         "2"
        ],
        [
         "6",
         "units_1",
         "8"
        ],
        [
         "7",
         "activation_0",
         "tanh"
        ],
        [
         "8",
         "lr",
         "0.0001787125964217817"
        ],
        [
         "9",
         "momentum",
         "0.0"
        ],
        [
         "10",
         "optimizer",
         "sgd"
        ],
        [
         "11",
         "units_2",
         "30"
        ],
        [
         "12",
         "activation_1",
         "LeakyReLU"
        ],
        [
         "13",
         "dropout_rate",
         "0.5"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 14
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperparameter</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bn_momentum</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>units</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>activation</td>\n",
       "      <td>tanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dropout</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num_layers</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>units_1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>activation_0</td>\n",
       "      <td>tanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>momentum</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>optimizer</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>units_2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>activation_1</td>\n",
       "      <td>LeakyReLU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dropout_rate</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hyperparameter      Value\n",
       "0     bn_momentum        0.6\n",
       "1           units         42\n",
       "2      activation       tanh\n",
       "3              l1       0.01\n",
       "4         dropout       True\n",
       "5      num_layers          2\n",
       "6         units_1          8\n",
       "7    activation_0       tanh\n",
       "8              lr   0.000179\n",
       "9        momentum        0.0\n",
       "10      optimizer        sgd\n",
       "11        units_2         30\n",
       "12   activation_1  LeakyReLU\n",
       "13   dropout_rate        0.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "# Making dataframe to show the best hyperparameters\n",
    "best_hps_dict = best_hps.values\n",
    "best_hps_df = pd.DataFrame(best_hps_dict.items(), columns=['Hyperparameter', 'Value'])\n",
    "best_hps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\murta\\Desktop\\Desktop\\ML&DE\\Fourth_Semester\\Advanced_ML\\.venv\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary of models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),  \n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=2, max_features=3),\n",
    "    \"SVR\": SVR(C=10, epsilon=0.1, kernel='rbf', gamma='scale'),\n",
    "    \"KNN\": KNeighborsRegressor(n_neighbors=15, weights='uniform', algorithm='auto'),\n",
    "    \"MLP Regressor\": MLPRegressor(hidden_layer_sizes=(128, 64, 32), activation='relu', solver='adam', early_stopping=True, alpha=0.01, learning_rate_init=0.001),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=10, min_samples_split=10),    \n",
    "    'Extra Trees Regressor': ExtraTreesRegressor(n_estimators=400, max_depth=20, min_samples_split=2, max_features='sqrt'),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(n_estimators=500, learning_rate=0.01, max_depth=10),\n",
    "    \"XGBoost\": xgb.XGBRegressor(n_estimators=400, learning_rate=0.01, max_depth=10), \n",
    "    'LightGBM': lgb.LGBMRegressor(n_estimators=500, learning_rate=0.01, max_depth=12, verbose=0),\n",
    "    'CatBoost': cb.CatBoostRegressor(n_estimators=400, learning_rate=0.01, depth=6, verbose=0),\n",
    "    'Neural Network': keras.models.Sequential(\n",
    "        [\n",
    "        layers.BatchNormalization(input_shape=(len(X.columns),)),   \n",
    "        layers.Dense(50, activation='tanh', kernel_regularizer=regularizers.l1(l1=0.02)),\n",
    "        layers.BatchNormalization( momentum=0.2),\n",
    "        layers.Dense(14, activation='tanh'),    \n",
    "        layers.BatchNormalization( momentum=0.2),   \n",
    "        layers.Dense(4, activation='relu'),    \n",
    "        layers.BatchNormalization(momentum=0.2),    \n",
    "        layers.Dense(1)\n",
    "    ]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ... Linear Regression\n",
      "Starting ... Random Forest Regressor\n",
      "Starting ... SVR\n",
      "Starting ... KNN\n",
      "Starting ... MLP Regressor\n",
      "Starting ... Decision Tree\n",
      "Starting ... Extra Trees Regressor\n",
      "Starting ... Gradient Boosting Regressor\n",
      "Starting ... XGBoost\n",
      "Starting ... LightGBM\n",
      "Starting ... CatBoost\n",
      "Starting ... Neural Network\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    }
   ],
   "source": [
    "# Creating a list to store the results\n",
    "results = []\n",
    "# for each model\n",
    "for name, model in models.items():\n",
    "    \n",
    "    print(\"Starting ... \"+ name)    \n",
    "    model.random_state = 78\n",
    "    # start the clock\n",
    "    start  = time.time()  \n",
    "      \n",
    "    if name == 'Neural Network':\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0048640356869126), loss='mse', metrics=['mean_absolute_error']) \n",
    "         # I need callback to stop the model when it is not improving and avoid overfitting.\n",
    "        callback = [\n",
    "          keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "          keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)\n",
    "          ]\n",
    "        \n",
    "        model.fit(X_train_scaled, y_train, validation_data= (X_val_scaled, y_val), callbacks=callback, epochs=100, batch_size=32, verbose=0) \n",
    "        predictions = model.predict(X_test_scaled)\n",
    "   # Since these model needs scaled data, I will use the scaled data\n",
    "    elif name in ['SVR', 'KNN', 'MLP Regressor']:\n",
    "    \n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "    end  = time.time()\n",
    "    Train_Time = round(end - start, 2)\n",
    "    # calculate the metrics\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    # append the results to the list\n",
    "    results.append([name, mae, mse, r2, Train_Time])\n",
    "    \n",
    "# I got the main code idea from lecture notes. But I changed the code for my own dataset.  I got some errors and I used LLM for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Train_Time",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "df1fe586-0d46-4190-8608-92e9940f31bf",
       "rows": [
        [
         "9",
         "LightGBM",
         "1.7497068490177243",
         "6.476290907418469",
         "0.8622473781799582",
         "0.88"
        ],
        [
         "6",
         "Extra Trees Regressor",
         "1.9195796014671944",
         "6.5764558047009105",
         "0.8601168412086826",
         "1.48"
        ],
        [
         "7",
         "Gradient Boosting Regressor",
         "1.7092342122598374",
         "6.810534189937242",
         "0.8551379247673643",
         "8.05"
        ],
        [
         "1",
         "Random Forest Regressor",
         "1.8992205399474764",
         "6.856324678624251",
         "0.8541639475385416",
         "2.18"
        ],
        [
         "8",
         "XGBoost",
         "1.7443292978236986",
         "7.032418227094177",
         "0.8504183857140194",
         "3.74"
        ],
        [
         "11",
         "Neural Network",
         "2.115607036328523",
         "7.278244306258196",
         "0.8451895923505535",
         "16.45"
        ],
        [
         "3",
         "KNN",
         "2.2059906666666667",
         "8.803995136131014",
         "0.8127364212278152",
         "0.01"
        ],
        [
         "2",
         "SVR",
         "2.2888625648854917",
         "8.863075399153162",
         "0.8114797665707805",
         "0.3"
        ],
        [
         "4",
         "MLP Regressor",
         "2.3941221265647283",
         "8.9164377007385",
         "0.8103447346435841",
         "1.95"
        ],
        [
         "5",
         "Decision Tree",
         "1.9735439457672965",
         "9.212849607856567",
         "0.804039965767711",
         "0.02"
        ],
        [
         "10",
         "CatBoost",
         "2.3849151105735107",
         "9.671613021635913",
         "0.7942819323583673",
         "0.95"
        ],
        [
         "0",
         "Linear Regression",
         "2.908310448839318",
         "11.94424834701156",
         "0.7459423072571025",
         "0.01"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Train_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.749707</td>\n",
       "      <td>6.476291</td>\n",
       "      <td>0.862247</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Extra Trees Regressor</td>\n",
       "      <td>1.919580</td>\n",
       "      <td>6.576456</td>\n",
       "      <td>0.860117</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>1.709234</td>\n",
       "      <td>6.810534</td>\n",
       "      <td>0.855138</td>\n",
       "      <td>8.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>1.899221</td>\n",
       "      <td>6.856325</td>\n",
       "      <td>0.854164</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.744329</td>\n",
       "      <td>7.032418</td>\n",
       "      <td>0.850418</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>2.115607</td>\n",
       "      <td>7.278244</td>\n",
       "      <td>0.845190</td>\n",
       "      <td>16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2.205991</td>\n",
       "      <td>8.803995</td>\n",
       "      <td>0.812736</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVR</td>\n",
       "      <td>2.288863</td>\n",
       "      <td>8.863075</td>\n",
       "      <td>0.811480</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP Regressor</td>\n",
       "      <td>2.394122</td>\n",
       "      <td>8.916438</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.973544</td>\n",
       "      <td>9.212850</td>\n",
       "      <td>0.804040</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>2.384915</td>\n",
       "      <td>9.671613</td>\n",
       "      <td>0.794282</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2.908310</td>\n",
       "      <td>11.944248</td>\n",
       "      <td>0.745942</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model       MAE        MSE        R2  Train_Time\n",
       "9                      LightGBM  1.749707   6.476291  0.862247        0.88\n",
       "6         Extra Trees Regressor  1.919580   6.576456  0.860117        1.48\n",
       "7   Gradient Boosting Regressor  1.709234   6.810534  0.855138        8.05\n",
       "1       Random Forest Regressor  1.899221   6.856325  0.854164        2.18\n",
       "8                       XGBoost  1.744329   7.032418  0.850418        3.74\n",
       "11               Neural Network  2.115607   7.278244  0.845190       16.45\n",
       "3                           KNN  2.205991   8.803995  0.812736        0.01\n",
       "2                           SVR  2.288863   8.863075  0.811480        0.30\n",
       "4                 MLP Regressor  2.394122   8.916438  0.810345        1.95\n",
       "5                 Decision Tree  1.973544   9.212850  0.804040        0.02\n",
       "10                     CatBoost  2.384915   9.671613  0.794282        0.95\n",
       "0             Linear Regression  2.908310  11.944248  0.745942        0.01"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'MAE', 'MSE', 'R2', 'Train_Time'])\n",
    "results_df.sort_values('R2', ascending=False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**what I can see here, LightGBM has better performance. It has higher R score and also has lower MAE and MSE.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
