{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_tuner\n",
    "from keras.regularizers import l1\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import layers\n",
    "from keras.regularizers import l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data \n",
    "df = pd.read_csv('dataset_classification/diabetes_012_health_indicators_BRFSS2015_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HighBP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HighChol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BMI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Stroke",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HeartDiseaseorAttack",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PhysActivity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HvyAlcoholConsump",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AnyHealthcare",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GenHlth",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PhysHlth",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DiffWalk",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Sex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Education",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Income",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Diabetes",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0f2d766f-e27f-4280-ad8b-ab168fad47e1",
       "rows": [
        [
         "0",
         "1.0",
         "1.0",
         "40.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "5.0",
         "15.0",
         "1.0",
         "0.0",
         "9.0",
         "4.0",
         "3.0",
         "0.0"
        ],
        [
         "1",
         "1.0",
         "0.0",
         "27.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "11.0",
         "3.0",
         "6.0",
         "0.0"
        ],
        [
         "2",
         "1.0",
         "1.0",
         "24.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "2.0",
         "0.0",
         "0.0",
         "0.0",
         "11.0",
         "5.0",
         "4.0",
         "0.0"
        ],
        [
         "3",
         "1.0",
         "1.0",
         "25.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "2.0",
         "2.0",
         "0.0",
         "1.0",
         "10.0",
         "6.0",
         "8.0",
         "0.0"
        ],
        [
         "4",
         "1.0",
         "0.0",
         "30.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "3.0",
         "14.0",
         "0.0",
         "0.0",
         "9.0",
         "6.0",
         "7.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol   BMI  Stroke  HeartDiseaseorAttack  PhysActivity  \\\n",
       "0     1.0       1.0  40.0     0.0                   0.0           0.0   \n",
       "1     1.0       0.0  27.0     0.0                   0.0           1.0   \n",
       "2     1.0       1.0  24.0     0.0                   0.0           1.0   \n",
       "3     1.0       1.0  25.0     0.0                   0.0           1.0   \n",
       "4     1.0       0.0  30.0     0.0                   0.0           0.0   \n",
       "\n",
       "   HvyAlcoholConsump  AnyHealthcare  GenHlth  PhysHlth  DiffWalk  Sex   Age  \\\n",
       "0                0.0            1.0      5.0      15.0       1.0  0.0   9.0   \n",
       "1                0.0            1.0      2.0       0.0       0.0  0.0  11.0   \n",
       "2                0.0            1.0      2.0       0.0       0.0  0.0  11.0   \n",
       "3                0.0            1.0      2.0       2.0       0.0  1.0  10.0   \n",
       "4                0.0            1.0      3.0      14.0       0.0  0.0   9.0   \n",
       "\n",
       "   Education  Income  Diabetes  \n",
       "0        4.0     3.0       0.0  \n",
       "1        3.0     6.0       0.0  \n",
       "2        5.0     4.0       0.0  \n",
       "3        6.0     8.0       0.0  \n",
       "4        6.0     7.0       0.0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191994, 16)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes\n",
       "0    166830\n",
       "2     21274\n",
       "1      3890\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Diabetes'].value_counts()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Diabetes', axis=1)\n",
    "y = df['Diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "X, y = unsersample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes\n",
       "2    21274\n",
       "0     3890\n",
       "1     3890\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (29054, 15)\n",
      "y_train shape: (29054,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X.shape)\n",
    "print(\"y_train shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy y values for converting classes to matrix\n",
    "y_train_n = y_train.copy()\n",
    "y_val_n = y_val.copy()\n",
    "y_test_n = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am gonna  tf.keras.utils.to_categorical  to convert classes into matrix. Since I will use other models as well, I copied y values.\n",
    "y_train_n= tf.keras.utils.to_categorical(y_train_n)\n",
    "y_val_n= tf.keras.utils.to_categorical(y_val_n)\n",
    "y_test_n= tf.keras.utils.to_categorical(y_test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_n: (20337, 3)\n",
      "y_val_n: (4358, 3)\n",
      "y_test_n: (4359, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train_n:\", y_train_n.shape)\n",
    "print(\"y_val_n:\", y_val_n.shape)\n",
    "print(\"y_test_n:\", y_test_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20337, 15)\n",
      "y_train shape: (20337,)\n",
      "X_val shape: (4358, 15)\n",
      "y_val shape: (4358,)\n",
      "X_test shape: (4359, 15)\n",
      "y_test shape: (4359,)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of the training, validation, and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the categories into a list \n",
    "categories = list(np.unique(df['Diabetes']))    \n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 22s]\n",
      "val_loss: 0.7612646818161011\n",
      "\n",
      "Best val_loss So Far: 0.7612083355585734\n",
      "Total elapsed time: 00h 27m 10s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a function to fine tune and adding hp object\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Adding the input layer\n",
    "    model.add(keras.layers.BatchNormalization(\n",
    "        momentum=hp.Float('bn_momentum', 0.1, 0.9, 0.1), input_shape=(len(X.columns),))),\n",
    "  \n",
    "     \n",
    "    \n",
    "    # First Hidden Layer \n",
    "    model.add(keras.layers.Dense(\n",
    "        units=hp.Int('units', min_value=32, max_value=256, step=4),\n",
    "        # For fine tuning the model, I am gonna use tow activation functions  relu and tanh\n",
    "        activation=hp.Choice('activation', ['relu', \"tanh\"]),\n",
    "        kernel_regularizer=keras.regularizers.l1(l1=hp.Float('l1', 0, 0.1, step=0.01),)\n",
    "    ))\n",
    "        \n",
    "    # Dropout layer\n",
    "    if hp.Boolean('dropout'):\n",
    "        model.add(keras.layers.Dropout(rate=hp.Float('dropout_rate', 0.1, 0.5, step=0.1)))\n",
    "        \n",
    "        \n",
    "    # Adding additional hidden layers\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 4)):\n",
    "        units = hp.Int(f\"units_{i+1}\", 16, 128, 2)\n",
    "        activation = hp.Choice(f\"activation_{i}\", ['relu', 'tanh', 'LeakyReLU'])\n",
    "        \n",
    "        if activation == 'LeakyReLU':\n",
    "           model.add(keras.layers.Dense(units))\n",
    "           model.add(keras.layers.LeakyReLU(negative_slope=hp.Float('leaky_relu_slope', 0.1, 0.5, step=0.1)))\n",
    "            \n",
    "        else:\n",
    "           model.add(keras.layers.Dense(units, activation=activation))\n",
    "           \n",
    "    model.add(layers.Dense(len(categories), activation=\"softmax\"))\n",
    "    \n",
    "    # Setting up the optimizer and compiling the model \n",
    "    learning_rate = hp.Float('lr', min_value=1e-4, max_value=5e-2, sampling=\"log\")\n",
    "    # Creating the dictionary for the optimizers for givin flexibility to the model\n",
    "    optimizers = {\n",
    "        'adam': keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        'sgd': keras.optimizers.SGD(learning_rate=learning_rate, momentum=hp.Float('momentum', 0.0, 0.9, 0.1)),\n",
    "        'rmsprop': keras.optimizers.RMSprop(learning_rate=learning_rate)}[hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])]\n",
    "    model.compile(optimizer=optimizers, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())\n",
    "# Setting up the Keras tuner\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel= build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    directory='dataset_classification/model_tuning',\n",
    "    project_name=\"classification_model\",\n",
    "    overwrite=True  \n",
    ")\n",
    "\n",
    "callback = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)\n",
    "]\n",
    "\n",
    "# Starting  searching\n",
    "tuner.search(X_train_scaled, y_train_n, epochs=250, validation_data=(X_val_scaled, y_val_n), callbacks=callback, batch_size=126)   \n",
    "\n",
    "# I got the main code from deep learning lecture notes and for debugging I used  Google and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in dataset_classification/model_tuning\\classification_model\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.9\n",
      "units: 128\n",
      "activation: relu\n",
      "l1: 0.0\n",
      "dropout: True\n",
      "num_layers: 3\n",
      "units_1: 46\n",
      "activation_0: tanh\n",
      "lr: 0.0009730546622782074\n",
      "momentum: 0.7000000000000001\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.4\n",
      "units_2: 30\n",
      "activation_1: relu\n",
      "units_3: 38\n",
      "activation_2: relu\n",
      "units_4: 106\n",
      "activation_3: LeakyReLU\n",
      "dropout_rate: 0.4\n",
      "Score: 0.9698121349016825\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.5\n",
      "units: 164\n",
      "activation: tanh\n",
      "l1: 0.03\n",
      "dropout: False\n",
      "num_layers: 4\n",
      "units_1: 96\n",
      "activation_0: LeakyReLU\n",
      "lr: 0.0007346830490058072\n",
      "momentum: 0.2\n",
      "optimizer: rmsprop\n",
      "leaky_relu_slope: 0.1\n",
      "units_2: 16\n",
      "activation_1: relu\n",
      "units_3: 16\n",
      "activation_2: relu\n",
      "units_4: 16\n",
      "activation_3: relu\n",
      "Score: 0.9745214581489563\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.1\n",
      "units: 56\n",
      "activation: tanh\n",
      "l1: 0.04\n",
      "dropout: False\n",
      "num_layers: 3\n",
      "units_1: 22\n",
      "activation_0: LeakyReLU\n",
      "lr: 0.005238760403591215\n",
      "momentum: 0.0\n",
      "optimizer: rmsprop\n",
      "leaky_relu_slope: 0.2\n",
      "units_2: 60\n",
      "activation_1: LeakyReLU\n",
      "units_3: 116\n",
      "activation_2: tanh\n",
      "units_4: 30\n",
      "activation_3: tanh\n",
      "dropout_rate: 0.1\n",
      "Score: 0.9796843330065409\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.4\n",
      "units: 144\n",
      "activation: tanh\n",
      "l1: 0.07\n",
      "dropout: True\n",
      "num_layers: 4\n",
      "units_1: 32\n",
      "activation_0: relu\n",
      "lr: 0.0005831556865897062\n",
      "momentum: 0.8\n",
      "optimizer: rmsprop\n",
      "leaky_relu_slope: 0.4\n",
      "units_2: 36\n",
      "activation_1: relu\n",
      "units_3: 96\n",
      "activation_2: LeakyReLU\n",
      "units_4: 124\n",
      "activation_3: relu\n",
      "dropout_rate: 0.4\n",
      "Score: 0.9802178343137106\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.30000000000000004\n",
      "units: 88\n",
      "activation: relu\n",
      "l1: 0.03\n",
      "dropout: True\n",
      "num_layers: 3\n",
      "units_1: 116\n",
      "activation_0: relu\n",
      "lr: 0.005622220605277361\n",
      "momentum: 0.7000000000000001\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.1\n",
      "units_2: 118\n",
      "activation_1: relu\n",
      "units_3: 106\n",
      "activation_2: LeakyReLU\n",
      "units_4: 28\n",
      "activation_3: tanh\n",
      "dropout_rate: 0.1\n",
      "Score: 0.986456036567688\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.5\n",
      "units: 228\n",
      "activation: relu\n",
      "l1: 0.02\n",
      "dropout: True\n",
      "num_layers: 3\n",
      "units_1: 102\n",
      "activation_0: LeakyReLU\n",
      "lr: 0.026087894710489962\n",
      "momentum: 0.4\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.4\n",
      "units_2: 54\n",
      "activation_1: tanh\n",
      "units_3: 50\n",
      "activation_2: LeakyReLU\n",
      "units_4: 24\n",
      "activation_3: LeakyReLU\n",
      "dropout_rate: 0.4\n",
      "Score: 0.9877884785334269\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.4\n",
      "units: 248\n",
      "activation: tanh\n",
      "l1: 0.05\n",
      "dropout: True\n",
      "num_layers: 4\n",
      "units_1: 54\n",
      "activation_0: relu\n",
      "lr: 0.00738013871664687\n",
      "momentum: 0.1\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.2\n",
      "units_2: 56\n",
      "activation_1: LeakyReLU\n",
      "units_3: 80\n",
      "activation_2: tanh\n",
      "units_4: 70\n",
      "activation_3: tanh\n",
      "dropout_rate: 0.2\n",
      "Score: 0.9916190505027771\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.4\n",
      "units: 124\n",
      "activation: relu\n",
      "l1: 0.01\n",
      "dropout: False\n",
      "num_layers: 2\n",
      "units_1: 106\n",
      "activation_0: relu\n",
      "lr: 0.0002572650285164159\n",
      "momentum: 0.4\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.4\n",
      "units_2: 72\n",
      "activation_1: relu\n",
      "units_3: 82\n",
      "activation_2: relu\n",
      "units_4: 112\n",
      "activation_3: tanh\n",
      "dropout_rate: 0.5\n",
      "Score: 0.992618461449941\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.9\n",
      "units: 116\n",
      "activation: tanh\n",
      "l1: 0.07\n",
      "dropout: True\n",
      "num_layers: 4\n",
      "units_1: 112\n",
      "activation_0: tanh\n",
      "lr: 0.013618397926908032\n",
      "momentum: 0.30000000000000004\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.2\n",
      "units_2: 46\n",
      "activation_1: LeakyReLU\n",
      "units_3: 20\n",
      "activation_2: tanh\n",
      "units_4: 48\n",
      "activation_3: relu\n",
      "dropout_rate: 0.4\n",
      "Score: 0.9965628186861674\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.30000000000000004\n",
      "units: 36\n",
      "activation: tanh\n",
      "l1: 0.05\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 76\n",
      "activation_0: tanh\n",
      "lr: 0.00017610737869865216\n",
      "momentum: 0.30000000000000004\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.5\n",
      "units_2: 68\n",
      "activation_1: tanh\n",
      "units_3: 106\n",
      "activation_2: tanh\n",
      "units_4: 44\n",
      "activation_3: relu\n",
      "dropout_rate: 0.1\n",
      "Score: 1.0331406195958455\n"
     ]
    }
   ],
   "source": [
    "# print out the result and suggestions\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Hyperparameter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Value",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4925e0c3-f19b-4136-ac4a-46e7c444bbe3",
       "rows": [
        [
         "0",
         "bn_momentum",
         "0.30000000000000004"
        ],
        [
         "1",
         "units",
         "76"
        ],
        [
         "2",
         "activation",
         "tanh"
        ],
        [
         "3",
         "l1",
         "0.08"
        ],
        [
         "4",
         "dropout",
         "True"
        ],
        [
         "5",
         "num_layers",
         "3"
        ],
        [
         "6",
         "units_1",
         "68"
        ],
        [
         "7",
         "activation_0",
         "LeakyReLU"
        ],
        [
         "8",
         "lr",
         "0.0002616798647325732"
        ],
        [
         "9",
         "momentum",
         "0.4"
        ],
        [
         "10",
         "optimizer",
         "sgd"
        ],
        [
         "11",
         "units_2",
         "120"
        ],
        [
         "12",
         "activation_1",
         "tanh"
        ],
        [
         "13",
         "units_3",
         "56"
        ],
        [
         "14",
         "activation_2",
         "LeakyReLU"
        ],
        [
         "15",
         "leaky_relu_slope",
         "0.30000000000000004"
        ],
        [
         "16",
         "units_4",
         "16"
        ],
        [
         "17",
         "activation_3",
         "tanh"
        ],
        [
         "18",
         "dropout_rate",
         "0.1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 19
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperparameter</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bn_momentum</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>units</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>activation</td>\n",
       "      <td>tanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dropout</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num_layers</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>units_1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>activation_0</td>\n",
       "      <td>LeakyReLU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>momentum</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>optimizer</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>units_2</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>activation_1</td>\n",
       "      <td>tanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>units_3</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>activation_2</td>\n",
       "      <td>LeakyReLU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>leaky_relu_slope</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>units_4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>activation_3</td>\n",
       "      <td>tanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dropout_rate</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hyperparameter      Value\n",
       "0        bn_momentum        0.3\n",
       "1              units         76\n",
       "2         activation       tanh\n",
       "3                 l1       0.08\n",
       "4            dropout       True\n",
       "5         num_layers          3\n",
       "6            units_1         68\n",
       "7       activation_0  LeakyReLU\n",
       "8                 lr   0.000262\n",
       "9           momentum        0.4\n",
       "10         optimizer        sgd\n",
       "11           units_2        120\n",
       "12      activation_1       tanh\n",
       "13           units_3         56\n",
       "14      activation_2  LeakyReLU\n",
       "15  leaky_relu_slope        0.3\n",
       "16           units_4         16\n",
       "17      activation_3       tanh\n",
       "18      dropout_rate        0.1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "# Making dataframe to show the best hyperparameters\n",
    "best_hps_dict = best_hps.values\n",
    "best_hps_df = pd.DataFrame(best_hps_dict.items(), columns=['Hyperparameter', 'Value'])\n",
    "best_hps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crating the category list for CatBoost model\n",
    "category_features = ['HighBP', 'HighChol','Stroke', 'PhysActivity',  'HeartDiseaseorAttack', 'HvyAlcoholConsump', 'AnyHealthcare', 'GenHlth', 'PhysHlth', 'DiffWalk', 'Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of classification models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(C=0.5, solver='saga', max_iter=1000, n_jobs=-1),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(n_estimators=500, max_depth=15, min_samples_split=5, max_features='sqrt'),\n",
    "    \n",
    "    \"SVC\": SVC(C=5, kernel='linear', probability=True, max_iter=120000),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=20, weights='distance', algorithm='auto',n_jobs=-1),    \n",
    "    \"MLP Classifier\": MLPClassifier(hidden_layer_sizes=(256, 128, 64), activation='relu', solver='adam', \n",
    "    early_stopping=True, alpha=0.0005, learning_rate_init=0.01, max_iter=1000),\n",
    "    \n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=15, min_samples_split=20, min_samples_leaf=10),\n",
    "    \"Extra Trees Classifier\": ExtraTreesClassifier(n_estimators=600, max_depth=25, min_samples_split=5, max_features='sqrt', n_jobs=-1),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(n_estimators=600, learning_rate=0.01, max_depth=15),\n",
    "    \n",
    "    \"XGBoost\": xgb.XGBClassifier(n_estimators=600, learning_rate=0.01, max_depth=15, \n",
    "    enable_categorical=True, objective='multi:softprob'), \n",
    "    \"LightGBM\": lgb.LGBMClassifier(n_estimators=500, learning_rate=0.01, max_depth=12, verbose=0, objective='multiclass'),\n",
    "    \"CatBoost\": cb.CatBoostClassifier(n_estimators=600, learning_rate=0.01, depth=6, verbose=0),\n",
    "    \n",
    "    \"Neural Network\": keras.models.Sequential([\n",
    "         keras.Input(shape=(len(X.columns),)),\n",
    "         layers.BatchNormalization( momentum=0.3),\n",
    "         layers.Dense(76, activation='tanh'),\n",
    "         layers.BatchNormalization(momentum=0.3),\n",
    "         layers.Dense(68, activation='tanh'),  \n",
    "         layers.BatchNormalization( momentum=0.3),\n",
    "         layers.Dense(120, activation='relu'),\n",
    "         layers.BatchNormalization(momentum=0.3),\n",
    "         layers.Dense(56, activation='relu'),\n",
    "         layers.BatchNormalization(momentum=0.3),      \n",
    "         layers.Dense(16, activation=LeakyReLU(negative_slope=0.4)),\n",
    "         layers.BatchNormalization(momentum=0.3),\n",
    "         layers.Dense(len(categories), activation='softmax')])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ... Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\murta\\Desktop\\Desktop\\ML&DE\\Fourth_Semester\\Advanced_ML\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ... Random Forest Classifier\n",
      "Starting ... SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\murta\\Desktop\\Desktop\\ML&DE\\Fourth_Semester\\Advanced_ML\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\murta\\Desktop\\Desktop\\ML&DE\\Fourth_Semester\\Advanced_ML\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ... KNN\n",
      "Starting ... MLP Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\murta\\Desktop\\Desktop\\ML&DE\\Fourth_Semester\\Advanced_ML\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ... Decision Tree\n",
      "Starting ... Extra Trees Classifier\n",
      "Starting ... Gradient Boosting Classifier\n",
      "Starting ... XGBoost\n",
      "Starting ... LightGBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\murta\\Desktop\\Desktop\\ML&DE\\Fourth_Semester\\Advanced_ML\\.venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\murta\\Desktop\\Desktop\\ML&DE\\Fourth_Semester\\Advanced_ML\\.venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"C:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 503, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"C:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 971, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 1456, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ... CatBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\murta\\Desktop\\Desktop\\ML&DE\\Fourth_Semester\\Advanced_ML\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ... Neural Network\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a list to store the results\n",
    "results = []\n",
    "# for each model\n",
    "for name, model in models.items():\n",
    "    print(\"Starting ... \" + name)\n",
    "    start = time.time()\n",
    "    # Training each model\n",
    "    if name == 'Neural Network':\n",
    "        model.compile(optimizer=keras.optimizers.SGD(\n",
    "        learning_rate=0.0002616798647325732), loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "        # Early Stopping \n",
    "        early_stop = keras.callbacks.EarlyStopping(\n",
    "        patience=10, monitor='val_loss', mode='min',\n",
    "        restore_best_weights=True)\n",
    "        # Fitting the model\n",
    "        model.fit(X_train_scaled, y_train_n,\n",
    "        validation_data=(X_val_scaled, y_val_n), \n",
    "        callbacks=[early_stop], epochs=500,\n",
    "        batch_size=64, verbose=0)\n",
    "        # mAking predictions\n",
    "        # I am going to use np.argmax to convert the matrix into classes\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        y_test_n = np.argmax(y_test_n, axis=1)\n",
    "        # Evaluating the model\n",
    "        accuracy = accuracy_score(y_test_n, predictions)\n",
    "        precision = precision_score(y_test_n, predictions, average=\"macro\")\n",
    "        recall = recall_score(y_test_n, predictions, average=\"macro\")\n",
    "        f1 = f1_score(y_test_n, predictions, average=\"macro\")\n",
    "\n",
    "\n",
    "\n",
    "    elif name in ['KNN', 'MLP Classifier', 'SVC']:\n",
    "        # Training with scaled data\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        probability = model.predict_proba(X_test_scaled) if hasattr(model, \"predict_proba\") else None\n",
    "        \n",
    "    elif name == 'CatBoost':\n",
    "        model.fit(X_train, y_train, cat_features=category_features, verbose=0)\n",
    "        predictions = model.predict(X_test)\n",
    "        probability = model.predict_proba(X_test)\n",
    "\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        probability = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    end = time.time()\n",
    "    Train_Time = round(end - start, 2)\n",
    "    # calculate the metrics\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    # Calculate metrics for current model in training\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions, average=\"macro\")\n",
    "    recall = recall_score(y_test, predictions, average=\"macro\")\n",
    "    f1 = f1_score(y_test, predictions, average=\"macro\")\n",
    "    # ROC AUC\n",
    "    if probability is not None:\n",
    "        y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
    "        roc_auc = roc_auc_score(y_test, probability, multi_class='ovr')\n",
    "    else:\n",
    "        roc_auc = np.nan\n",
    "\n",
    "    # save the metrics for this model into results\n",
    "    results.append([name, accuracy, precision, recall, f1, roc_auc, Train_Time])\n",
    "    \n",
    " #I got the main code from the lecture notes, and for debugging, I used Google and an LLM here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ROC AUC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Time",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "136a03c1-7107-4b69-8cb1-5bf5fa090b15",
       "rows": [
        [
         "5",
         "Decision Tree",
         "0.7058958476714843",
         "0.45277623170117226",
         "0.431476413349601",
         "0.4308122950974907",
         "0.6350750716532134",
         "0.05"
        ],
        [
         "8",
         "XGBoost",
         "0.726542785042441",
         "0.481117849382805",
         "0.4256919570720495",
         "0.4240380413956652",
         "0.6570044878925226",
         "21.2"
        ],
        [
         "9",
         "LightGBM",
         "0.7490250057352604",
         "0.709854164704784",
         "0.428141693128343",
         "0.42149363640133447",
         "0.6918427789193852",
         "1.97"
        ],
        [
         "7",
         "Gradient Boosting Classifier",
         "0.7102546455609084",
         "0.45572101071698173",
         "0.41632568215568994",
         "0.41794985804287127",
         "0.6305405035144506",
         "923.01"
        ],
        [
         "1",
         "Random Forest Classifier",
         "0.7469603119981647",
         "0.5758003424188775",
         "0.4233664376640461",
         "0.4169801020547261",
         "0.6851784052714178",
         "6.06"
        ],
        [
         "6",
         "Extra Trees Classifier",
         "0.7426015141087405",
         "0.5237694487176302",
         "0.4206778873275672",
         "0.41606551823028975",
         "0.6735682845657675",
         "2.62"
        ],
        [
         "10",
         "CatBoost",
         "0.7478779536590962",
         "0.44635783482501495",
         "0.42108525488273413",
         "0.4127931924045267",
         "0.6908936518788863",
         "32.45"
        ],
        [
         "0",
         "Logistic Regression",
         "0.7469603119981647",
         "0.44159115060538356",
         "0.4216222801821837",
         "0.41258667791266407",
         "0.6863928431267888",
         "3.08"
        ],
        [
         "3",
         "KNN",
         "0.7159899059417297",
         "0.33437796548103965",
         "0.3340262610309408",
         "0.2922873313274826",
         "0.5147939878495792",
         "1.65"
        ],
        [
         "2",
         "SVC",
         "0.7276898371186051",
         "0.24256327903953503",
         "0.3333333333333333",
         "0.2807949364847519",
         "0.4988159032069622",
         "37.23"
        ],
        [
         "4",
         "MLP Classifier",
         "0.7276898371186051",
         "0.24256327903953503",
         "0.3333333333333333",
         "0.2807949364847519",
         "0.5005712433276678",
         "5.3"
        ],
        [
         "11",
         "Neural Network",
         "0.7270016058729066",
         "0.24250076522803796",
         "0.33301807482135354",
         "0.28064116188452",
         "0.6908936518788863",
         "55.04"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.705896</td>\n",
       "      <td>0.452776</td>\n",
       "      <td>0.431476</td>\n",
       "      <td>0.430812</td>\n",
       "      <td>0.635075</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.726543</td>\n",
       "      <td>0.481118</td>\n",
       "      <td>0.425692</td>\n",
       "      <td>0.424038</td>\n",
       "      <td>0.657004</td>\n",
       "      <td>21.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.749025</td>\n",
       "      <td>0.709854</td>\n",
       "      <td>0.428142</td>\n",
       "      <td>0.421494</td>\n",
       "      <td>0.691843</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.710255</td>\n",
       "      <td>0.455721</td>\n",
       "      <td>0.416326</td>\n",
       "      <td>0.417950</td>\n",
       "      <td>0.630541</td>\n",
       "      <td>923.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.746960</td>\n",
       "      <td>0.575800</td>\n",
       "      <td>0.423366</td>\n",
       "      <td>0.416980</td>\n",
       "      <td>0.685178</td>\n",
       "      <td>6.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>0.742602</td>\n",
       "      <td>0.523769</td>\n",
       "      <td>0.420678</td>\n",
       "      <td>0.416066</td>\n",
       "      <td>0.673568</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.747878</td>\n",
       "      <td>0.446358</td>\n",
       "      <td>0.421085</td>\n",
       "      <td>0.412793</td>\n",
       "      <td>0.690894</td>\n",
       "      <td>32.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.746960</td>\n",
       "      <td>0.441591</td>\n",
       "      <td>0.421622</td>\n",
       "      <td>0.412587</td>\n",
       "      <td>0.686393</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.715990</td>\n",
       "      <td>0.334378</td>\n",
       "      <td>0.334026</td>\n",
       "      <td>0.292287</td>\n",
       "      <td>0.514794</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.727690</td>\n",
       "      <td>0.242563</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.280795</td>\n",
       "      <td>0.498816</td>\n",
       "      <td>37.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>0.727690</td>\n",
       "      <td>0.242563</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.280795</td>\n",
       "      <td>0.500571</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.727002</td>\n",
       "      <td>0.242501</td>\n",
       "      <td>0.333018</td>\n",
       "      <td>0.280641</td>\n",
       "      <td>0.690894</td>\n",
       "      <td>55.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Accuracy  Precision    Recall        F1  \\\n",
       "5                  Decision Tree  0.705896   0.452776  0.431476  0.430812   \n",
       "8                        XGBoost  0.726543   0.481118  0.425692  0.424038   \n",
       "9                       LightGBM  0.749025   0.709854  0.428142  0.421494   \n",
       "7   Gradient Boosting Classifier  0.710255   0.455721  0.416326  0.417950   \n",
       "1       Random Forest Classifier  0.746960   0.575800  0.423366  0.416980   \n",
       "6         Extra Trees Classifier  0.742602   0.523769  0.420678  0.416066   \n",
       "10                      CatBoost  0.747878   0.446358  0.421085  0.412793   \n",
       "0            Logistic Regression  0.746960   0.441591  0.421622  0.412587   \n",
       "3                            KNN  0.715990   0.334378  0.334026  0.292287   \n",
       "2                            SVC  0.727690   0.242563  0.333333  0.280795   \n",
       "4                 MLP Classifier  0.727690   0.242563  0.333333  0.280795   \n",
       "11                Neural Network  0.727002   0.242501  0.333018  0.280641   \n",
       "\n",
       "     ROC AUC    Time  \n",
       "5   0.635075    0.05  \n",
       "8   0.657004   21.20  \n",
       "9   0.691843    1.97  \n",
       "7   0.630541  923.01  \n",
       "1   0.685178    6.06  \n",
       "6   0.673568    2.62  \n",
       "10  0.690894   32.45  \n",
       "0   0.686393    3.08  \n",
       "3   0.514794    1.65  \n",
       "2   0.498816   37.23  \n",
       "4   0.500571    5.30  \n",
       "11  0.690894   55.04  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', \"Precision\", \"Recall\", \"F1\", \"ROC AUC\", 'Time'])\n",
    "results_df.sort_values('F1', ascending=False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From these results, I see that XGBoost and CatBoost have better performing,  this makes sense because they use boosting methods.**<br>\n",
    "**On the other hand, Logistic Regression and Decision Tree train very quickly and are easy to explaim, but their accuracy is lower.**<br>\n",
    "**If I want the best performance and have enough time, I would choose XGBoost or CatBoost.**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the results\n",
    "results_df.to_csv('dataset_classification/results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
