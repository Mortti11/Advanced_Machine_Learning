{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 203,
>>>>>>> 3f24c42b2f7d9accba4f1ee4de1b814eabb6b367
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_tuner\n",
<<<<<<< HEAD
    "from keras.regularizers import l1\n",
    "from keras.layers import LeakyReLU"
=======
    "from keras import layers\n",
    "from keras.regularizers import l1\n"
>>>>>>> 3f24c42b2f7d9accba4f1ee4de1b814eabb6b367
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data \n",
    "df = pd.read_csv('dataset_classification/diabetes_012_health_indicators_BRFSS2015_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol   BMI  Stroke  HeartDiseaseorAttack  PhysActivity  \\\n",
       "0     1.0       1.0  40.0     0.0                   0.0           0.0   \n",
       "1     1.0       0.0  27.0     0.0                   0.0           1.0   \n",
       "2     1.0       1.0  24.0     0.0                   0.0           1.0   \n",
       "3     1.0       1.0  25.0     0.0                   0.0           1.0   \n",
       "4     1.0       0.0  30.0     0.0                   0.0           0.0   \n",
       "\n",
       "   HvyAlcoholConsump  AnyHealthcare  GenHlth  PhysHlth  DiffWalk  Sex   Age  \\\n",
       "0                0.0            1.0      5.0      15.0       1.0  0.0   9.0   \n",
       "1                0.0            1.0      2.0       0.0       0.0  0.0  11.0   \n",
       "2                0.0            1.0      2.0       0.0       0.0  0.0  11.0   \n",
       "3                0.0            1.0      2.0       2.0       0.0  1.0  10.0   \n",
       "4                0.0            1.0      3.0      14.0       0.0  0.0   9.0   \n",
       "\n",
       "   Education  Income  Diabetes  \n",
       "0        4.0     3.0       0.0  \n",
       "1        3.0     6.0       0.0  \n",
       "2        5.0     4.0       0.0  \n",
       "3        6.0     8.0       0.0  \n",
       "4        6.0     7.0       0.0  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191994, 16)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes\n",
       "0    166830\n",
       "2     21274\n",
       "1      3890\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Diabetes'].value_counts()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Diabetes', axis=1)\n",
    "y = df['Diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes\n",
       "0    166830\n",
       "2    166830\n",
       "1    166830\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (500490, 15)\n",
      "y_train shape: (500490,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X.shape)\n",
    "print(\"y_train shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_n = y_train.copy()\n",
    "y_val_n = y_val.copy()\n",
    "y_test_n = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_n= tf.keras.utils.to_categorical(y_train_n)\n",
    "y_val_n= tf.keras.utils.to_categorical(y_val_n)\n",
    "y_test_n= tf.keras.utils.to_categorical(y_test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_n: (350343, 3)\n",
      "y_val_n: (75073, 3)\n",
      "y_test_n: (75074, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train_n:\", y_train_n.shape)\n",
    "print(\"y_val_n:\", y_val_n.shape)\n",
    "print(\"y_test_n:\", y_test_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (350343, 15)\n",
      "y_train shape: (350343,)\n",
      "X_val shape: (75073, 15)\n",
      "y_val shape: (75073,)\n",
      "X_test shape: (75074, 15)\n",
      "y_test shape: (75074,)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of the training, validation, and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the categories into a list \n",
    "categories = list(np.unique(df['Diabetes']))    \n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.7               |0.7               |bn_momentum\n",
      "88                |88                |units\n",
      "tanh              |tanh              |activation\n",
      "0.03              |0.03              |l1\n",
      "True              |True              |dropout\n",
      "1                 |1                 |num_layers\n",
      "90                |90                |units_1\n",
      "tanh              |tanh              |activation_0\n",
      "0.00074442        |0.00074442        |lr\n",
      "0.5               |0.5               |momentum\n",
      "sgd               |sgd               |optimizer\n",
      "\n",
      "Epoch 1/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4344 - loss: 5.3342 - val_accuracy: 0.5101 - val_loss: 3.7069 - learning_rate: 7.4442e-04\n",
      "Epoch 2/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5110 - loss: 3.2846 - val_accuracy: 0.5165 - val_loss: 2.1895 - learning_rate: 7.4442e-04\n",
      "Epoch 3/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5154 - loss: 1.9265 - val_accuracy: 0.5170 - val_loss: 1.3200 - learning_rate: 7.4442e-04\n",
      "Epoch 4/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5174 - loss: 1.2181 - val_accuracy: 0.5084 - val_loss: 1.0679 - learning_rate: 7.4442e-04\n",
      "Epoch 5/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5092 - loss: 1.0573 - val_accuracy: 0.5052 - val_loss: 1.0405 - learning_rate: 7.4442e-04\n",
      "Epoch 6/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5077 - loss: 1.0350 - val_accuracy: 0.5065 - val_loss: 1.0251 - learning_rate: 7.4442e-04\n",
      "Epoch 7/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5091 - loss: 1.0224 - val_accuracy: 0.5078 - val_loss: 1.0150 - learning_rate: 7.4442e-04\n",
      "Epoch 8/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5091 - loss: 1.0131 - val_accuracy: 0.5089 - val_loss: 1.0076 - learning_rate: 7.4442e-04\n",
      "Epoch 9/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5091 - loss: 1.0075 - val_accuracy: 0.5093 - val_loss: 1.0030 - learning_rate: 7.4442e-04\n",
      "Epoch 10/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5093 - loss: 1.0030 - val_accuracy: 0.5109 - val_loss: 0.9993 - learning_rate: 7.4442e-04\n",
      "Epoch 11/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5108 - loss: 1.0003 - val_accuracy: 0.5119 - val_loss: 0.9967 - learning_rate: 7.4442e-04\n",
      "Epoch 12/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5080 - loss: 0.9992 - val_accuracy: 0.5121 - val_loss: 0.9940 - learning_rate: 7.4442e-04\n",
      "Epoch 13/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5103 - loss: 0.9953 - val_accuracy: 0.5102 - val_loss: 0.9916 - learning_rate: 7.4442e-04\n",
      "Epoch 14/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5104 - loss: 0.9939 - val_accuracy: 0.5124 - val_loss: 0.9906 - learning_rate: 7.4442e-04\n",
      "Epoch 15/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5089 - loss: 0.9946 - val_accuracy: 0.5120 - val_loss: 0.9892 - learning_rate: 7.4442e-04\n",
      "Epoch 16/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5106 - loss: 0.9925 - val_accuracy: 0.5136 - val_loss: 0.9883 - learning_rate: 7.4442e-04\n",
      "Epoch 17/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5116 - loss: 0.9898 - val_accuracy: 0.5135 - val_loss: 0.9873 - learning_rate: 7.4442e-04\n",
      "Epoch 18/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5112 - loss: 0.9897 - val_accuracy: 0.5127 - val_loss: 0.9861 - learning_rate: 7.4442e-04\n",
      "Epoch 19/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5112 - loss: 0.9876 - val_accuracy: 0.5133 - val_loss: 0.9856 - learning_rate: 7.4442e-04\n",
      "Epoch 20/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5119 - loss: 0.9877 - val_accuracy: 0.5142 - val_loss: 0.9845 - learning_rate: 7.4442e-04\n",
      "Epoch 21/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5111 - loss: 0.9868 - val_accuracy: 0.5134 - val_loss: 0.9841 - learning_rate: 7.4442e-04\n",
      "Epoch 22/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5128 - loss: 0.9857 - val_accuracy: 0.5114 - val_loss: 0.9832 - learning_rate: 7.4442e-04\n",
      "Epoch 23/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5125 - loss: 0.9849 - val_accuracy: 0.5130 - val_loss: 0.9832 - learning_rate: 7.4442e-04\n",
      "Epoch 24/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5123 - loss: 0.9848 - val_accuracy: 0.5138 - val_loss: 0.9821 - learning_rate: 7.4442e-04\n",
      "Epoch 25/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5121 - loss: 0.9847 - val_accuracy: 0.5134 - val_loss: 0.9820 - learning_rate: 7.4442e-04\n",
      "Epoch 26/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5126 - loss: 0.9842 - val_accuracy: 0.5146 - val_loss: 0.9814 - learning_rate: 7.4442e-04\n",
      "Epoch 27/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5134 - loss: 0.9837 - val_accuracy: 0.5142 - val_loss: 0.9808 - learning_rate: 7.4442e-04\n",
      "Epoch 28/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5133 - loss: 0.9836 - val_accuracy: 0.5148 - val_loss: 0.9802 - learning_rate: 7.4442e-04\n",
      "Epoch 29/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5121 - loss: 0.9840 - val_accuracy: 0.5143 - val_loss: 0.9801 - learning_rate: 7.4442e-04\n",
      "Epoch 30/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5129 - loss: 0.9812 - val_accuracy: 0.5139 - val_loss: 0.9795 - learning_rate: 7.4442e-04\n",
      "Epoch 31/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5144 - loss: 0.9806 - val_accuracy: 0.5141 - val_loss: 0.9793 - learning_rate: 7.4442e-04\n",
      "Epoch 32/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.9803 - val_accuracy: 0.5134 - val_loss: 0.9797 - learning_rate: 7.4442e-04\n",
      "Epoch 33/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5128 - loss: 0.9808 - val_accuracy: 0.5145 - val_loss: 0.9786 - learning_rate: 7.4442e-04\n",
      "Epoch 34/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5151 - loss: 0.9794 - val_accuracy: 0.5144 - val_loss: 0.9776 - learning_rate: 7.4442e-04\n",
      "Epoch 35/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5140 - loss: 0.9798 - val_accuracy: 0.5153 - val_loss: 0.9778 - learning_rate: 7.4442e-04\n",
      "Epoch 36/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5125 - loss: 0.9803 - val_accuracy: 0.5146 - val_loss: 0.9775 - learning_rate: 7.4442e-04\n",
      "Epoch 37/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5154 - loss: 0.9785 - val_accuracy: 0.5153 - val_loss: 0.9775 - learning_rate: 7.4442e-04\n",
      "Epoch 38/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5141 - loss: 0.9792 - val_accuracy: 0.5139 - val_loss: 0.9770 - learning_rate: 7.4442e-04\n",
      "Epoch 39/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5164 - loss: 0.9774 - val_accuracy: 0.5155 - val_loss: 0.9770 - learning_rate: 7.4442e-04\n",
      "Epoch 40/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5143 - loss: 0.9792 - val_accuracy: 0.5150 - val_loss: 0.9767 - learning_rate: 7.4442e-04\n",
      "Epoch 41/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5163 - loss: 0.9766 - val_accuracy: 0.5161 - val_loss: 0.9768 - learning_rate: 7.4442e-04\n",
      "Epoch 42/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5148 - loss: 0.9785 - val_accuracy: 0.5150 - val_loss: 0.9762 - learning_rate: 7.4442e-04\n",
      "Epoch 43/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5147 - loss: 0.9769 - val_accuracy: 0.5144 - val_loss: 0.9763 - learning_rate: 7.4442e-04\n",
      "Epoch 44/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5141 - loss: 0.9768 - val_accuracy: 0.5157 - val_loss: 0.9757 - learning_rate: 7.4442e-04\n",
      "Epoch 45/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5140 - loss: 0.9784 - val_accuracy: 0.5155 - val_loss: 0.9752 - learning_rate: 7.4442e-04\n",
      "Epoch 46/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5152 - loss: 0.9771 - val_accuracy: 0.5149 - val_loss: 0.9758 - learning_rate: 7.4442e-04\n",
      "Epoch 47/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5156 - loss: 0.9772 - val_accuracy: 0.5159 - val_loss: 0.9749 - learning_rate: 7.4442e-04\n",
      "Epoch 48/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5165 - loss: 0.9753 - val_accuracy: 0.5161 - val_loss: 0.9749 - learning_rate: 7.4442e-04\n",
      "Epoch 49/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5161 - loss: 0.9755 - val_accuracy: 0.5149 - val_loss: 0.9749 - learning_rate: 7.4442e-04\n",
      "Epoch 50/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5175 - loss: 0.9756 - val_accuracy: 0.5174 - val_loss: 0.9748 - learning_rate: 7.4442e-04\n",
      "Epoch 51/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5169 - loss: 0.9755 - val_accuracy: 0.5154 - val_loss: 0.9744 - learning_rate: 7.4442e-04\n",
      "Epoch 52/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5159 - loss: 0.9742 - val_accuracy: 0.5171 - val_loss: 0.9742 - learning_rate: 7.4442e-04\n",
      "Epoch 53/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5149 - loss: 0.9761 - val_accuracy: 0.5159 - val_loss: 0.9741 - learning_rate: 7.4442e-04\n",
      "Epoch 54/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5175 - loss: 0.9756 - val_accuracy: 0.5157 - val_loss: 0.9739 - learning_rate: 7.4442e-04\n",
      "Epoch 55/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.9750 - val_accuracy: 0.5170 - val_loss: 0.9737 - learning_rate: 7.4442e-04\n",
      "Epoch 56/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5166 - loss: 0.9753 - val_accuracy: 0.5171 - val_loss: 0.9736 - learning_rate: 7.4442e-04\n",
      "Epoch 57/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5143 - loss: 0.9748 - val_accuracy: 0.5157 - val_loss: 0.9739 - learning_rate: 7.4442e-04\n",
      "Epoch 58/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5146 - loss: 0.9751 - val_accuracy: 0.5157 - val_loss: 0.9735 - learning_rate: 7.4442e-04\n",
      "Epoch 59/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5160 - loss: 0.9750 - val_accuracy: 0.5153 - val_loss: 0.9734 - learning_rate: 7.4442e-04\n",
      "Epoch 60/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5142 - loss: 0.9758 - val_accuracy: 0.5163 - val_loss: 0.9727 - learning_rate: 7.4442e-04\n",
      "Epoch 61/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5162 - loss: 0.9745 - val_accuracy: 0.5160 - val_loss: 0.9732 - learning_rate: 7.4442e-04\n",
      "Epoch 62/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5158 - loss: 0.9737 - val_accuracy: 0.5171 - val_loss: 0.9728 - learning_rate: 7.4442e-04\n",
      "Epoch 63/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5157 - loss: 0.9754 - val_accuracy: 0.5170 - val_loss: 0.9728 - learning_rate: 7.4442e-04\n",
      "Epoch 64/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5166 - loss: 0.9736 - val_accuracy: 0.5162 - val_loss: 0.9721 - learning_rate: 7.4442e-04\n",
      "Epoch 65/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5151 - loss: 0.9755 - val_accuracy: 0.5169 - val_loss: 0.9723 - learning_rate: 7.4442e-04\n",
      "Epoch 66/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5176 - loss: 0.9738 - val_accuracy: 0.5169 - val_loss: 0.9724 - learning_rate: 7.4442e-04\n",
      "Epoch 67/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5165 - loss: 0.9728 - val_accuracy: 0.5181 - val_loss: 0.9721 - learning_rate: 7.4442e-04\n",
      "Epoch 68/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5170 - loss: 0.9724 - val_accuracy: 0.5161 - val_loss: 0.9724 - learning_rate: 7.4442e-04\n",
      "Epoch 69/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5147 - loss: 0.9743 - val_accuracy: 0.5164 - val_loss: 0.9723 - learning_rate: 7.4442e-04\n",
      "Epoch 70/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5161 - loss: 0.9721 - val_accuracy: 0.5162 - val_loss: 0.9716 - learning_rate: 1.4888e-04\n",
      "Epoch 71/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5152 - loss: 0.9739 - val_accuracy: 0.5170 - val_loss: 0.9708 - learning_rate: 1.4888e-04\n",
      "Epoch 72/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.9720 - val_accuracy: 0.5172 - val_loss: 0.9711 - learning_rate: 1.4888e-04\n",
      "Epoch 73/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5166 - loss: 0.9720 - val_accuracy: 0.5178 - val_loss: 0.9710 - learning_rate: 1.4888e-04\n",
      "Epoch 74/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5153 - loss: 0.9732 - val_accuracy: 0.5178 - val_loss: 0.9709 - learning_rate: 1.4888e-04\n",
      "Epoch 75/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5163 - loss: 0.9730 - val_accuracy: 0.5168 - val_loss: 0.9705 - learning_rate: 1.4888e-04\n",
      "Epoch 76/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5168 - loss: 0.9726 - val_accuracy: 0.5171 - val_loss: 0.9706 - learning_rate: 1.4888e-04\n",
      "Epoch 77/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5149 - loss: 0.9733 - val_accuracy: 0.5174 - val_loss: 0.9709 - learning_rate: 1.4888e-04\n",
      "Epoch 78/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5148 - loss: 0.9732 - val_accuracy: 0.5160 - val_loss: 0.9705 - learning_rate: 1.4888e-04\n",
      "Epoch 79/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5165 - loss: 0.9731 - val_accuracy: 0.5167 - val_loss: 0.9707 - learning_rate: 1.4888e-04\n",
      "Epoch 80/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5171 - loss: 0.9719 - val_accuracy: 0.5175 - val_loss: 0.9707 - learning_rate: 1.4888e-04\n",
      "Epoch 81/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5160 - loss: 0.9718 - val_accuracy: 0.5167 - val_loss: 0.9704 - learning_rate: 2.9777e-05\n",
      "Epoch 82/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5147 - loss: 0.9737 - val_accuracy: 0.5181 - val_loss: 0.9707 - learning_rate: 2.9777e-05\n",
      "Epoch 83/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5159 - loss: 0.9736 - val_accuracy: 0.5172 - val_loss: 0.9705 - learning_rate: 2.9777e-05\n",
      "Epoch 84/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.9712 - val_accuracy: 0.5176 - val_loss: 0.9705 - learning_rate: 2.9777e-05\n",
      "Epoch 85/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5179 - loss: 0.9717 - val_accuracy: 0.5170 - val_loss: 0.9705 - learning_rate: 2.9777e-05\n",
      "Epoch 86/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5162 - loss: 0.9723 - val_accuracy: 0.5172 - val_loss: 0.9705 - learning_rate: 5.9553e-06\n",
      "Epoch 87/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5151 - loss: 0.9723 - val_accuracy: 0.5173 - val_loss: 0.9704 - learning_rate: 5.9553e-06\n",
      "Epoch 88/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5157 - loss: 0.9726 - val_accuracy: 0.5170 - val_loss: 0.9705 - learning_rate: 5.9553e-06\n",
      "Epoch 89/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5168 - loss: 0.9713 - val_accuracy: 0.5165 - val_loss: 0.9704 - learning_rate: 5.9553e-06\n",
      "Epoch 90/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5161 - loss: 0.9724 - val_accuracy: 0.5177 - val_loss: 0.9706 - learning_rate: 5.9553e-06\n",
      "Epoch 91/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5175 - loss: 0.9716 - val_accuracy: 0.5164 - val_loss: 0.9709 - learning_rate: 5.9553e-06\n",
      "Epoch 92/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5179 - loss: 0.9715 - val_accuracy: 0.5177 - val_loss: 0.9707 - learning_rate: 5.9553e-06\n",
      "Epoch 93/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5168 - loss: 0.9720 - val_accuracy: 0.5173 - val_loss: 0.9702 - learning_rate: 1.1911e-06\n",
      "Epoch 94/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5169 - loss: 0.9734 - val_accuracy: 0.5170 - val_loss: 0.9703 - learning_rate: 1.1911e-06\n",
      "Epoch 95/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5151 - loss: 0.9722 - val_accuracy: 0.5166 - val_loss: 0.9706 - learning_rate: 1.1911e-06\n",
      "Epoch 96/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5168 - loss: 0.9706 - val_accuracy: 0.5172 - val_loss: 0.9705 - learning_rate: 1.1911e-06\n",
      "Epoch 97/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5155 - loss: 0.9731 - val_accuracy: 0.5158 - val_loss: 0.9710 - learning_rate: 1.1911e-06\n",
      "Epoch 98/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5170 - loss: 0.9708 - val_accuracy: 0.5167 - val_loss: 0.9711 - learning_rate: 1.1911e-06\n",
      "Epoch 99/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5159 - loss: 0.9725 - val_accuracy: 0.5175 - val_loss: 0.9705 - learning_rate: 2.3821e-07\n",
      "Epoch 100/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5166 - loss: 0.9717 - val_accuracy: 0.5174 - val_loss: 0.9705 - learning_rate: 2.3821e-07\n",
      "Epoch 101/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5179 - loss: 0.9720 - val_accuracy: 0.5173 - val_loss: 0.9703 - learning_rate: 2.3821e-07\n",
      "Epoch 102/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5171 - loss: 0.9720 - val_accuracy: 0.5174 - val_loss: 0.9703 - learning_rate: 2.3821e-07\n",
      "Epoch 103/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5168 - loss: 0.9723 - val_accuracy: 0.5173 - val_loss: 0.9705 - learning_rate: 2.3821e-07\n",
      "Epoch 1/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4128 - loss: 5.2905 - val_accuracy: 0.5078 - val_loss: 3.6357 - learning_rate: 7.4442e-04\n",
      "Epoch 2/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5101 - loss: 3.2197 - val_accuracy: 0.5188 - val_loss: 2.1418 - learning_rate: 7.4442e-04\n",
      "Epoch 3/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5175 - loss: 1.8833 - val_accuracy: 0.5191 - val_loss: 1.2996 - learning_rate: 7.4442e-04\n",
      "Epoch 4/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5176 - loss: 1.2027 - val_accuracy: 0.5124 - val_loss: 1.0602 - learning_rate: 7.4442e-04\n",
      "Epoch 5/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5114 - loss: 1.0514 - val_accuracy: 0.5083 - val_loss: 1.0367 - learning_rate: 7.4442e-04\n",
      "Epoch 6/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5119 - loss: 1.0302 - val_accuracy: 0.5099 - val_loss: 1.0232 - learning_rate: 7.4442e-04\n",
      "Epoch 7/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5128 - loss: 1.0197 - val_accuracy: 0.5110 - val_loss: 1.0148 - learning_rate: 7.4442e-04\n",
      "Epoch 8/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 1.0114 - val_accuracy: 0.5113 - val_loss: 1.0087 - learning_rate: 7.4442e-04\n",
      "Epoch 9/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5140 - loss: 1.0077 - val_accuracy: 0.5115 - val_loss: 1.0044 - learning_rate: 7.4442e-04\n",
      "Epoch 10/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5123 - loss: 1.0044 - val_accuracy: 0.5113 - val_loss: 1.0010 - learning_rate: 7.4442e-04\n",
      "Epoch 11/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5130 - loss: 1.0010 - val_accuracy: 0.5118 - val_loss: 0.9975 - learning_rate: 7.4442e-04\n",
      "Epoch 12/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5120 - loss: 0.9983 - val_accuracy: 0.5125 - val_loss: 0.9955 - learning_rate: 7.4442e-04\n",
      "Epoch 13/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5129 - loss: 0.9956 - val_accuracy: 0.5119 - val_loss: 0.9926 - learning_rate: 7.4442e-04\n",
      "Epoch 14/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5141 - loss: 0.9930 - val_accuracy: 0.5121 - val_loss: 0.9908 - learning_rate: 7.4442e-04\n",
      "Epoch 15/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 0.9919 - val_accuracy: 0.5130 - val_loss: 0.9891 - learning_rate: 7.4442e-04\n",
      "Epoch 16/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5140 - loss: 0.9897 - val_accuracy: 0.5133 - val_loss: 0.9876 - learning_rate: 7.4442e-04\n",
      "Epoch 17/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 0.9898 - val_accuracy: 0.5128 - val_loss: 0.9864 - learning_rate: 7.4442e-04\n",
      "Epoch 18/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5114 - loss: 0.9882 - val_accuracy: 0.5143 - val_loss: 0.9855 - learning_rate: 7.4442e-04\n",
      "Epoch 19/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5128 - loss: 0.9877 - val_accuracy: 0.5143 - val_loss: 0.9848 - learning_rate: 7.4442e-04\n",
      "Epoch 20/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5126 - loss: 0.9868 - val_accuracy: 0.5154 - val_loss: 0.9841 - learning_rate: 7.4442e-04\n",
      "Epoch 21/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.9855 - val_accuracy: 0.5142 - val_loss: 0.9829 - learning_rate: 7.4442e-04\n",
      "Epoch 22/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 0.9838 - val_accuracy: 0.5146 - val_loss: 0.9825 - learning_rate: 7.4442e-04\n",
      "Epoch 23/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5144 - loss: 0.9827 - val_accuracy: 0.5162 - val_loss: 0.9821 - learning_rate: 7.4442e-04\n",
      "Epoch 24/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5130 - loss: 0.9843 - val_accuracy: 0.5149 - val_loss: 0.9812 - learning_rate: 7.4442e-04\n",
      "Epoch 25/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5149 - loss: 0.9829 - val_accuracy: 0.5155 - val_loss: 0.9811 - learning_rate: 7.4442e-04\n",
      "Epoch 26/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5148 - loss: 0.9821 - val_accuracy: 0.5157 - val_loss: 0.9804 - learning_rate: 7.4442e-04\n",
      "Epoch 27/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5156 - loss: 0.9821 - val_accuracy: 0.5158 - val_loss: 0.9802 - learning_rate: 7.4442e-04\n",
      "Epoch 28/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5155 - loss: 0.9814 - val_accuracy: 0.5159 - val_loss: 0.9799 - learning_rate: 7.4442e-04\n",
      "Epoch 29/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5143 - loss: 0.9812 - val_accuracy: 0.5154 - val_loss: 0.9788 - learning_rate: 7.4442e-04\n",
      "Epoch 30/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5148 - loss: 0.9799 - val_accuracy: 0.5156 - val_loss: 0.9783 - learning_rate: 7.4442e-04\n",
      "Epoch 31/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5156 - loss: 0.9806 - val_accuracy: 0.5165 - val_loss: 0.9783 - learning_rate: 7.4442e-04\n",
      "Epoch 32/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5140 - loss: 0.9807 - val_accuracy: 0.5146 - val_loss: 0.9784 - learning_rate: 7.4442e-04\n",
      "Epoch 33/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5160 - loss: 0.9800 - val_accuracy: 0.5156 - val_loss: 0.9778 - learning_rate: 7.4442e-04\n",
      "Epoch 34/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5144 - loss: 0.9785 - val_accuracy: 0.5150 - val_loss: 0.9775 - learning_rate: 7.4442e-04\n",
      "Epoch 35/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5142 - loss: 0.9805 - val_accuracy: 0.5157 - val_loss: 0.9771 - learning_rate: 7.4442e-04\n",
      "Epoch 36/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5139 - loss: 0.9788 - val_accuracy: 0.5163 - val_loss: 0.9769 - learning_rate: 7.4442e-04\n",
      "Epoch 37/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5159 - loss: 0.9782 - val_accuracy: 0.5162 - val_loss: 0.9765 - learning_rate: 7.4442e-04\n",
      "Epoch 38/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5154 - loss: 0.9775 - val_accuracy: 0.5156 - val_loss: 0.9767 - learning_rate: 7.4442e-04\n",
      "Epoch 39/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5152 - loss: 0.9770 - val_accuracy: 0.5164 - val_loss: 0.9757 - learning_rate: 7.4442e-04\n",
      "Epoch 40/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5136 - loss: 0.9765 - val_accuracy: 0.5158 - val_loss: 0.9757 - learning_rate: 7.4442e-04\n",
      "Epoch 41/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5160 - loss: 0.9770 - val_accuracy: 0.5141 - val_loss: 0.9758 - learning_rate: 7.4442e-04\n",
      "Epoch 42/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5138 - loss: 0.9787 - val_accuracy: 0.5160 - val_loss: 0.9752 - learning_rate: 7.4442e-04\n",
      "Epoch 43/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 0.9778 - val_accuracy: 0.5138 - val_loss: 0.9755 - learning_rate: 7.4442e-04\n",
      "Epoch 44/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5160 - loss: 0.9758 - val_accuracy: 0.5162 - val_loss: 0.9748 - learning_rate: 7.4442e-04\n",
      "Epoch 45/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5154 - loss: 0.9765 - val_accuracy: 0.5160 - val_loss: 0.9749 - learning_rate: 7.4442e-04\n",
      "Epoch 46/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 0.9769 - val_accuracy: 0.5163 - val_loss: 0.9748 - learning_rate: 7.4442e-04\n",
      "Epoch 47/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5162 - loss: 0.9757 - val_accuracy: 0.5170 - val_loss: 0.9746 - learning_rate: 7.4442e-04\n",
      "Epoch 48/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5157 - loss: 0.9763 - val_accuracy: 0.5173 - val_loss: 0.9743 - learning_rate: 7.4442e-04\n",
      "Epoch 49/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5173 - loss: 0.9745 - val_accuracy: 0.5159 - val_loss: 0.9741 - learning_rate: 7.4442e-04\n",
      "Epoch 50/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5159 - loss: 0.9756 - val_accuracy: 0.5178 - val_loss: 0.9745 - learning_rate: 7.4442e-04\n",
      "Epoch 51/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5155 - loss: 0.9756 - val_accuracy: 0.5165 - val_loss: 0.9732 - learning_rate: 7.4442e-04\n",
      "Epoch 52/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5161 - loss: 0.9752 - val_accuracy: 0.5150 - val_loss: 0.9736 - learning_rate: 7.4442e-04\n",
      "Epoch 53/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5158 - loss: 0.9747 - val_accuracy: 0.5159 - val_loss: 0.9741 - learning_rate: 7.4442e-04\n",
      "Epoch 54/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5163 - loss: 0.9751 - val_accuracy: 0.5159 - val_loss: 0.9730 - learning_rate: 7.4442e-04\n",
      "Epoch 55/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5170 - loss: 0.9746 - val_accuracy: 0.5162 - val_loss: 0.9730 - learning_rate: 7.4442e-04\n",
      "Epoch 56/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5177 - loss: 0.9739 - val_accuracy: 0.5152 - val_loss: 0.9733 - learning_rate: 7.4442e-04\n",
      "Epoch 57/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5175 - loss: 0.9737 - val_accuracy: 0.5166 - val_loss: 0.9727 - learning_rate: 7.4442e-04\n",
      "Epoch 58/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5166 - loss: 0.9740 - val_accuracy: 0.5165 - val_loss: 0.9731 - learning_rate: 7.4442e-04\n",
      "Epoch 59/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5150 - loss: 0.9746 - val_accuracy: 0.5166 - val_loss: 0.9724 - learning_rate: 7.4442e-04\n",
      "Epoch 60/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5162 - loss: 0.9743 - val_accuracy: 0.5155 - val_loss: 0.9726 - learning_rate: 7.4442e-04\n",
      "Epoch 61/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5156 - loss: 0.9737 - val_accuracy: 0.5169 - val_loss: 0.9728 - learning_rate: 7.4442e-04\n",
      "Epoch 62/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5165 - loss: 0.9745 - val_accuracy: 0.5179 - val_loss: 0.9723 - learning_rate: 7.4442e-04\n",
      "Epoch 63/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5146 - loss: 0.9738 - val_accuracy: 0.5165 - val_loss: 0.9721 - learning_rate: 7.4442e-04\n",
      "Epoch 64/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5162 - loss: 0.9733 - val_accuracy: 0.5172 - val_loss: 0.9723 - learning_rate: 7.4442e-04\n",
      "Epoch 65/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.9736 - val_accuracy: 0.5163 - val_loss: 0.9720 - learning_rate: 7.4442e-04\n",
      "Epoch 66/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5175 - loss: 0.9734 - val_accuracy: 0.5167 - val_loss: 0.9719 - learning_rate: 7.4442e-04\n",
      "Epoch 67/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5163 - loss: 0.9741 - val_accuracy: 0.5176 - val_loss: 0.9715 - learning_rate: 7.4442e-04\n",
      "Epoch 68/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5170 - loss: 0.9729 - val_accuracy: 0.5172 - val_loss: 0.9717 - learning_rate: 7.4442e-04\n",
      "Epoch 69/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5166 - loss: 0.9728 - val_accuracy: 0.5157 - val_loss: 0.9713 - learning_rate: 7.4442e-04\n",
      "Epoch 70/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5159 - loss: 0.9730 - val_accuracy: 0.5162 - val_loss: 0.9717 - learning_rate: 7.4442e-04\n",
      "Epoch 71/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5170 - loss: 0.9729 - val_accuracy: 0.5167 - val_loss: 0.9714 - learning_rate: 7.4442e-04\n",
      "Epoch 72/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5165 - loss: 0.9727 - val_accuracy: 0.5174 - val_loss: 0.9709 - learning_rate: 7.4442e-04\n",
      "Epoch 73/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5170 - loss: 0.9716 - val_accuracy: 0.5171 - val_loss: 0.9714 - learning_rate: 7.4442e-04\n",
      "Epoch 74/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.9727 - val_accuracy: 0.5178 - val_loss: 0.9719 - learning_rate: 7.4442e-04\n",
      "Epoch 75/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5178 - loss: 0.9717 - val_accuracy: 0.5175 - val_loss: 0.9709 - learning_rate: 7.4442e-04\n",
      "Epoch 76/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5162 - loss: 0.9737 - val_accuracy: 0.5167 - val_loss: 0.9706 - learning_rate: 7.4442e-04\n",
      "Epoch 77/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5175 - loss: 0.9719 - val_accuracy: 0.5177 - val_loss: 0.9715 - learning_rate: 7.4442e-04\n",
      "Epoch 78/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5155 - loss: 0.9730 - val_accuracy: 0.5172 - val_loss: 0.9710 - learning_rate: 7.4442e-04\n",
      "Epoch 79/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5158 - loss: 0.9728 - val_accuracy: 0.5179 - val_loss: 0.9708 - learning_rate: 7.4442e-04\n",
      "Epoch 80/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.9732 - val_accuracy: 0.5172 - val_loss: 0.9703 - learning_rate: 7.4442e-04\n",
      "Epoch 81/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5161 - loss: 0.9734 - val_accuracy: 0.5164 - val_loss: 0.9706 - learning_rate: 7.4442e-04\n",
      "Epoch 82/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5163 - loss: 0.9718 - val_accuracy: 0.5170 - val_loss: 0.9706 - learning_rate: 7.4442e-04\n",
      "Epoch 83/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5178 - loss: 0.9713 - val_accuracy: 0.5187 - val_loss: 0.9701 - learning_rate: 7.4442e-04\n",
      "Epoch 84/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5165 - loss: 0.9718 - val_accuracy: 0.5175 - val_loss: 0.9705 - learning_rate: 7.4442e-04\n",
      "Epoch 85/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5159 - loss: 0.9721 - val_accuracy: 0.5162 - val_loss: 0.9701 - learning_rate: 7.4442e-04\n",
      "Epoch 86/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5155 - loss: 0.9724 - val_accuracy: 0.5170 - val_loss: 0.9700 - learning_rate: 7.4442e-04\n",
      "Epoch 87/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.9717 - val_accuracy: 0.5169 - val_loss: 0.9698 - learning_rate: 7.4442e-04\n",
      "Epoch 88/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5185 - loss: 0.9708 - val_accuracy: 0.5178 - val_loss: 0.9697 - learning_rate: 7.4442e-04\n",
      "Epoch 89/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5169 - loss: 0.9710 - val_accuracy: 0.5167 - val_loss: 0.9697 - learning_rate: 7.4442e-04\n",
      "Epoch 90/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5187 - loss: 0.9710 - val_accuracy: 0.5178 - val_loss: 0.9694 - learning_rate: 7.4442e-04\n",
      "Epoch 91/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5168 - loss: 0.9710 - val_accuracy: 0.5169 - val_loss: 0.9695 - learning_rate: 7.4442e-04\n",
      "Epoch 92/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5147 - loss: 0.9727 - val_accuracy: 0.5181 - val_loss: 0.9694 - learning_rate: 7.4442e-04\n",
      "Epoch 93/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5179 - loss: 0.9709 - val_accuracy: 0.5179 - val_loss: 0.9693 - learning_rate: 7.4442e-04\n",
      "Epoch 94/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5161 - loss: 0.9715 - val_accuracy: 0.5186 - val_loss: 0.9701 - learning_rate: 7.4442e-04\n",
      "Epoch 95/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5177 - loss: 0.9705 - val_accuracy: 0.5175 - val_loss: 0.9695 - learning_rate: 7.4442e-04\n",
      "Epoch 96/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5163 - loss: 0.9717 - val_accuracy: 0.5185 - val_loss: 0.9690 - learning_rate: 7.4442e-04\n",
      "Epoch 97/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5182 - loss: 0.9707 - val_accuracy: 0.5181 - val_loss: 0.9695 - learning_rate: 7.4442e-04\n",
      "Epoch 98/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5182 - loss: 0.9702 - val_accuracy: 0.5185 - val_loss: 0.9691 - learning_rate: 7.4442e-04\n",
      "Epoch 99/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5181 - loss: 0.9707 - val_accuracy: 0.5180 - val_loss: 0.9691 - learning_rate: 7.4442e-04\n",
      "Epoch 100/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5157 - loss: 0.9705 - val_accuracy: 0.5184 - val_loss: 0.9692 - learning_rate: 7.4442e-04\n",
      "Epoch 101/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5176 - loss: 0.9716 - val_accuracy: 0.5176 - val_loss: 0.9692 - learning_rate: 7.4442e-04\n",
      "Epoch 102/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5173 - loss: 0.9706 - val_accuracy: 0.5177 - val_loss: 0.9680 - learning_rate: 1.4888e-04\n",
      "Epoch 103/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5167 - loss: 0.9701 - val_accuracy: 0.5179 - val_loss: 0.9679 - learning_rate: 1.4888e-04\n",
      "Epoch 104/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5166 - loss: 0.9697 - val_accuracy: 0.5184 - val_loss: 0.9678 - learning_rate: 1.4888e-04\n",
      "Epoch 105/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5179 - loss: 0.9693 - val_accuracy: 0.5179 - val_loss: 0.9680 - learning_rate: 1.4888e-04\n",
      "Epoch 106/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5181 - loss: 0.9698 - val_accuracy: 0.5182 - val_loss: 0.9680 - learning_rate: 1.4888e-04\n",
      "Epoch 107/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5166 - loss: 0.9695 - val_accuracy: 0.5188 - val_loss: 0.9678 - learning_rate: 1.4888e-04\n",
      "Epoch 108/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5167 - loss: 0.9700 - val_accuracy: 0.5180 - val_loss: 0.9677 - learning_rate: 1.4888e-04\n",
      "Epoch 109/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5176 - loss: 0.9693 - val_accuracy: 0.5177 - val_loss: 0.9684 - learning_rate: 1.4888e-04\n",
      "Epoch 110/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5164 - loss: 0.9693 - val_accuracy: 0.5179 - val_loss: 0.9676 - learning_rate: 1.4888e-04\n",
      "Epoch 111/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5189 - loss: 0.9667 - val_accuracy: 0.5183 - val_loss: 0.9674 - learning_rate: 1.4888e-04\n",
      "Epoch 112/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5181 - loss: 0.9696 - val_accuracy: 0.5183 - val_loss: 0.9678 - learning_rate: 1.4888e-04\n",
      "Epoch 113/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5171 - loss: 0.9703 - val_accuracy: 0.5178 - val_loss: 0.9679 - learning_rate: 1.4888e-04\n",
      "Epoch 114/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5162 - loss: 0.9698 - val_accuracy: 0.5190 - val_loss: 0.9677 - learning_rate: 1.4888e-04\n",
      "Epoch 115/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5187 - loss: 0.9694 - val_accuracy: 0.5187 - val_loss: 0.9677 - learning_rate: 1.4888e-04\n",
      "Epoch 116/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.9700 - val_accuracy: 0.5178 - val_loss: 0.9675 - learning_rate: 1.4888e-04\n",
      "Epoch 117/250\n",
      "\u001b[1m1369/1369\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5172 - loss: 0.9696 - val_accuracy: 0.5179 - val_loss: 0.9677 - learning_rate: 2.9777e-05\n",
      "Epoch 118/250\n",
      "\u001b[1m 387/1369\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5173 - loss: 0.9693"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 68\u001b[0m\n\u001b[0;32m     62\u001b[0m callback \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     63\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     64\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     65\u001b[0m ]\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Starting  searching\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_n\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m   \n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    242\u001b[0m     ):\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    255\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Creating a function to fine tune and adding hp object\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Adding the input layer\n",
    "    model.add(keras.layers.BatchNormalization(\n",
    "        momentum=hp.Float('bn_momentum', 0.1, 0.9, 0.1), input_shape=(len(X.columns),))),\n",
    "  \n",
    "     \n",
    "    \n",
    "    # First Hidden Layer \n",
    "    model.add(keras.layers.Dense(\n",
    "        units=hp.Int('units', min_value=32, max_value=256, step=4),\n",
    "        # For fine tuning the model, I am gonna use tow activation functions  relu and tanh\n",
    "        activation=hp.Choice('activation', ['relu', \"tanh\"]),\n",
    "        kernel_regularizer=keras.regularizers.l1(l1=hp.Float('l1', 0, 0.1, step=0.01),)\n",
    "    ))\n",
    "        \n",
    "    # Dropout layer\n",
    "    if hp.Boolean('dropout'):\n",
    "        model.add(keras.layers.Dropout(rate=hp.Float('dropout_rate', 0.1, 0.5, step=0.1)))\n",
    "        \n",
    "        \n",
    "    # Adding additional hidden layers\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 4)):\n",
    "        units = hp.Int(f\"units_{i+1}\", 16, 128, 2)\n",
    "        activation = hp.Choice(f\"activation_{i}\", ['relu', 'tanh', 'LeakyReLU'])\n",
    "        \n",
    "        if activation == 'LeakyReLU':\n",
    "           model.add(keras.layers.Dense(units))\n",
    "           model.add(keras.layers.LeakyReLU(negative_slope=hp.Float('leaky_relu_slope', 0.1, 0.5, step=0.1)))\n",
    "            \n",
    "        else:\n",
    "           model.add(keras.layers.Dense(units, activation=activation))\n",
    "           \n",
    "    model.add(layers.Dense(len(categories), activation=\"softmax\"))\n",
    "    \n",
    "    # Setting up the optimizer and compiling the model \n",
    "    learning_rate = hp.Float('lr', min_value=1e-4, max_value=5e-2, sampling=\"log\")\n",
    "    # Creating the dictionary for the optimizers for givin flexibility to the model\n",
    "    optimizers = {\n",
    "        'adam': keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        'sgd': keras.optimizers.SGD(learning_rate=learning_rate, momentum=hp.Float('momentum', 0.0, 0.9, 0.1)),\n",
    "        'rmsprop': keras.optimizers.RMSprop(learning_rate=learning_rate)}[hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])]\n",
    "    model.compile(optimizer=optimizers, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())\n",
    "# Setting up the Keras tuner\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel= build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    directory='dataset_classification/model_tuning',\n",
    "    project_name=\"classification_model\",\n",
    "    overwrite=True  \n",
    ")\n",
    "\n",
    "callback = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)\n",
    "]\n",
    "\n",
    "# Starting  searching\n",
    "tuner.search(X_train_scaled, y_train_n, epochs=250, validation_data=(X_val_scaled, y_val_n), callbacks=callback, verbose=1, batch_size=256)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in dataset_classification/model_tuning\\classification_model\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.9\n",
      "units: 128\n",
      "activation: relu\n",
      "l1: 0.0\n",
      "dropout: True\n",
      "num_layers: 3\n",
      "units_1: 46\n",
      "activation_0: tanh\n",
      "lr: 0.0009730546622782074\n",
      "momentum: 0.7000000000000001\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.4\n",
      "units_2: 30\n",
      "activation_1: relu\n",
      "units_3: 38\n",
      "activation_2: relu\n",
      "units_4: 106\n",
      "activation_3: LeakyReLU\n",
      "dropout_rate: 0.4\n",
      "Score: 0.9698121349016825\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.5\n",
      "units: 164\n",
      "activation: tanh\n",
      "l1: 0.03\n",
      "dropout: False\n",
      "num_layers: 4\n",
      "units_1: 96\n",
      "activation_0: LeakyReLU\n",
      "lr: 0.0007346830490058072\n",
      "momentum: 0.2\n",
      "optimizer: rmsprop\n",
      "leaky_relu_slope: 0.1\n",
      "units_2: 16\n",
      "activation_1: relu\n",
      "units_3: 16\n",
      "activation_2: relu\n",
      "units_4: 16\n",
      "activation_3: relu\n",
      "Score: 0.9745214581489563\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.1\n",
      "units: 56\n",
      "activation: tanh\n",
      "l1: 0.04\n",
      "dropout: False\n",
      "num_layers: 3\n",
      "units_1: 22\n",
      "activation_0: LeakyReLU\n",
      "lr: 0.005238760403591215\n",
      "momentum: 0.0\n",
      "optimizer: rmsprop\n",
      "leaky_relu_slope: 0.2\n",
      "units_2: 60\n",
      "activation_1: LeakyReLU\n",
      "units_3: 116\n",
      "activation_2: tanh\n",
      "units_4: 30\n",
      "activation_3: tanh\n",
      "dropout_rate: 0.1\n",
      "Score: 0.9796843330065409\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.4\n",
      "units: 144\n",
      "activation: tanh\n",
      "l1: 0.07\n",
      "dropout: True\n",
      "num_layers: 4\n",
      "units_1: 32\n",
      "activation_0: relu\n",
      "lr: 0.0005831556865897062\n",
      "momentum: 0.8\n",
      "optimizer: rmsprop\n",
      "leaky_relu_slope: 0.4\n",
      "units_2: 36\n",
      "activation_1: relu\n",
      "units_3: 96\n",
      "activation_2: LeakyReLU\n",
      "units_4: 124\n",
      "activation_3: relu\n",
      "dropout_rate: 0.4\n",
      "Score: 0.9802178343137106\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.30000000000000004\n",
      "units: 88\n",
      "activation: relu\n",
      "l1: 0.03\n",
      "dropout: True\n",
      "num_layers: 3\n",
      "units_1: 116\n",
      "activation_0: relu\n",
      "lr: 0.005622220605277361\n",
      "momentum: 0.7000000000000001\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.1\n",
      "units_2: 118\n",
      "activation_1: relu\n",
      "units_3: 106\n",
      "activation_2: LeakyReLU\n",
      "units_4: 28\n",
      "activation_3: tanh\n",
      "dropout_rate: 0.1\n",
      "Score: 0.986456036567688\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.5\n",
      "units: 228\n",
      "activation: relu\n",
      "l1: 0.02\n",
      "dropout: True\n",
      "num_layers: 3\n",
      "units_1: 102\n",
      "activation_0: LeakyReLU\n",
      "lr: 0.026087894710489962\n",
      "momentum: 0.4\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.4\n",
      "units_2: 54\n",
      "activation_1: tanh\n",
      "units_3: 50\n",
      "activation_2: LeakyReLU\n",
      "units_4: 24\n",
      "activation_3: LeakyReLU\n",
      "dropout_rate: 0.4\n",
      "Score: 0.9877884785334269\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.4\n",
      "units: 248\n",
      "activation: tanh\n",
      "l1: 0.05\n",
      "dropout: True\n",
      "num_layers: 4\n",
      "units_1: 54\n",
      "activation_0: relu\n",
      "lr: 0.00738013871664687\n",
      "momentum: 0.1\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.2\n",
      "units_2: 56\n",
      "activation_1: LeakyReLU\n",
      "units_3: 80\n",
      "activation_2: tanh\n",
      "units_4: 70\n",
      "activation_3: tanh\n",
      "dropout_rate: 0.2\n",
      "Score: 0.9916190505027771\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.4\n",
      "units: 124\n",
      "activation: relu\n",
      "l1: 0.01\n",
      "dropout: False\n",
      "num_layers: 2\n",
      "units_1: 106\n",
      "activation_0: relu\n",
      "lr: 0.0002572650285164159\n",
      "momentum: 0.4\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.4\n",
      "units_2: 72\n",
      "activation_1: relu\n",
      "units_3: 82\n",
      "activation_2: relu\n",
      "units_4: 112\n",
      "activation_3: tanh\n",
      "dropout_rate: 0.5\n",
      "Score: 0.992618461449941\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.9\n",
      "units: 116\n",
      "activation: tanh\n",
      "l1: 0.07\n",
      "dropout: True\n",
      "num_layers: 4\n",
      "units_1: 112\n",
      "activation_0: tanh\n",
      "lr: 0.013618397926908032\n",
      "momentum: 0.30000000000000004\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.2\n",
      "units_2: 46\n",
      "activation_1: LeakyReLU\n",
      "units_3: 20\n",
      "activation_2: tanh\n",
      "units_4: 48\n",
      "activation_3: relu\n",
      "dropout_rate: 0.4\n",
      "Score: 0.9965628186861674\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "bn_momentum: 0.30000000000000004\n",
      "units: 36\n",
      "activation: tanh\n",
      "l1: 0.05\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 76\n",
      "activation_0: tanh\n",
      "lr: 0.00017610737869865216\n",
      "momentum: 0.30000000000000004\n",
      "optimizer: sgd\n",
      "leaky_relu_slope: 0.5\n",
      "units_2: 68\n",
      "activation_1: tanh\n",
      "units_3: 106\n",
      "activation_2: tanh\n",
      "units_4: 44\n",
      "activation_3: relu\n",
      "dropout_rate: 0.1\n",
      "Score: 1.0331406195958455\n"
     ]
    }
   ],
   "source": [
    "# print out the result and suggestions\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\murta\\Desktop\\Desktop\\ML&DE\\Fourth_Semester\\Advanced_ML\\.venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'SGD', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "c:\\Users\\murta\\Desktop\\Desktop\\ML&DE\\Fourth_Semester\\Advanced_ML\\.venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,410</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,178</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │            \u001b[38;5;34m60\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)             │         \u001b[38;5;34m5,934\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m1,410\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m)             │         \u001b[38;5;34m1,178\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m117\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,747</span> (41.98 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,747\u001b[0m (41.98 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,717</span> (41.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,717\u001b[0m (41.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> (120.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m30\u001b[0m (120.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Hyperparameter",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Value",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8c3d8b4f-179f-408b-aed5-7c096ad6eca1",
       "rows": [
        [
         "0",
         "bn_momentum",
         "0.9"
        ],
        [
         "1",
         "units",
         "128"
        ],
        [
         "2",
         "activation",
         "relu"
        ],
        [
         "3",
         "l1",
         "0.0"
        ],
        [
         "4",
         "dropout",
         "True"
        ],
        [
         "5",
         "num_layers",
         "3"
        ],
        [
         "6",
         "units_1",
         "46"
        ],
        [
         "7",
         "activation_0",
         "tanh"
        ],
        [
         "8",
         "lr",
         "0.0009730546622782074"
        ],
        [
         "9",
         "momentum",
         "0.7000000000000001"
        ],
        [
         "10",
         "optimizer",
         "sgd"
        ],
        [
         "11",
         "leaky_relu_slope",
         "0.4"
        ],
        [
         "12",
         "units_2",
         "30"
        ],
        [
         "13",
         "activation_1",
         "relu"
        ],
        [
         "14",
         "units_3",
         "38"
        ],
        [
         "15",
         "activation_2",
         "relu"
        ],
        [
         "16",
         "units_4",
         "106"
        ],
        [
         "17",
         "activation_3",
         "LeakyReLU"
        ],
        [
         "18",
         "dropout_rate",
         "0.4"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 19
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperparameter</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bn_momentum</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>units</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>activation</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dropout</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num_layers</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>units_1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>activation_0</td>\n",
       "      <td>tanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>momentum</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>optimizer</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>leaky_relu_slope</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>units_2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>activation_1</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>units_3</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>activation_2</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>units_4</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>activation_3</td>\n",
       "      <td>LeakyReLU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dropout_rate</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hyperparameter      Value\n",
       "0        bn_momentum        0.9\n",
       "1              units        128\n",
       "2         activation       relu\n",
       "3                 l1        0.0\n",
       "4            dropout       True\n",
       "5         num_layers          3\n",
       "6            units_1         46\n",
       "7       activation_0       tanh\n",
       "8                 lr   0.000973\n",
       "9           momentum        0.7\n",
       "10         optimizer        sgd\n",
       "11  leaky_relu_slope        0.4\n",
       "12           units_2         30\n",
       "13      activation_1       relu\n",
       "14           units_3         38\n",
       "15      activation_2       relu\n",
       "16           units_4        106\n",
       "17      activation_3  LeakyReLU\n",
       "18      dropout_rate        0.4"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "# Making dataframe to show the best hyperparameters\n",
    "best_hps_dict = best_hps.values\n",
    "best_hps_df = pd.DataFrame(best_hps_dict.items(), columns=['Hyperparameter', 'Value'])\n",
    "best_hps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes  HighBP  HighChol  BMI  Stroke  HeartDiseaseorAttack  \\\n",
       "0         0       1         1   40       0                     0   \n",
       "1         0       0         0   25       0                     0   \n",
       "2         0       1         1   28       0                     0   \n",
       "3         0       1         0   27       0                     0   \n",
       "4         0       1         1   24       0                     0   \n",
       "\n",
       "   PhysActivity  HvyAlcoholConsump  AnyHealthcare  GenHlth  PhysHlth  \\\n",
       "0             0                  0              1        5        15   \n",
       "1             1                  0              0        3         0   \n",
       "2             0                  0              1        5        30   \n",
       "3             1                  0              1        2         0   \n",
       "4             1                  0              1        2         0   \n",
       "\n",
       "   DiffWalk  Sex  Age  Education  Income  \n",
       "0         1    0    9          4       3  \n",
       "1         0    0    7          6       1  \n",
       "2         1    0    9          4       8  \n",
       "3         0    0   11          3       6  \n",
       "4         0    0   11          5       4  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_features = ['HighBP', 'HighChol','Stroke', 'PhysActivity',  'HeartDiseaseorAttack', 'HvyAlcoholConsump', 'AnyHealthcare', 'GenHlth', 'PhysHlth', 'DiffWalk', 'Sex']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 225,
>>>>>>> 3f24c42b2f7d9accba4f1ee4de1b814eabb6b367
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of classification models\n",
    "models = {\n",
    "    #\"Logistic Regression\": LogisticRegression(C=0.5, solver='saga', max_iter=1000, n_jobs=-1),\n",
    "    #\"Random Forest Classifier\": RandomForestClassifier(n_estimators=500, max_depth=15, min_samples_split=5, max_features='sqrt'),\n",
    "    #\"SVC\": SVC(C=5, kernel='linear', probability=True, cache_size=1000, max_iter=10000),\n",
    "    #\"KNN\": KNeighborsClassifier(n_neighbors=20, weights='distance', algorithm='auto',n_jobs=-1),    \n",
    "    #\"MLP Classifier\": MLPClassifier(hidden_layer_sizes=(256, 128, 64), activation='relu', solver='adam', \n",
    "    #                                early_stopping=True, alpha=0.0005, learning_rate_init=0.01, max_iter=1000),\n",
    "    #\"Decision Tree\": DecisionTreeClassifier(max_depth=15, min_samples_split=20, min_samples_leaf=10),\n",
    "    #\"Extra Trees Classifier\": ExtraTreesClassifier(n_estimators=600, max_depth=25, min_samples_split=5, max_features='sqrt', n_jobs=-1),\n",
    "    #\"Gradient Boosting Classifier\": GradientBoostingClassifier(n_estimators=600, learning_rate=0.01, max_depth=15),\n",
    "   # \"XGBoost\": xgb.XGBClassifier(n_estimators=600, learning_rate=0.01, max_depth=15, \n",
    "                               # enable_categorical=True, objective='multi:softprobar', num_class=len(X.columns)), \n",
    "    #\"LightGBM\": lgb.LGBMClassifier(n_estimators=500, learning_rate=0.01, max_depth=12, verbose=0, objective='multiclass'),\n",
    "    \"CatBoost\": cb.CatBoostClassifier(n_estimators=600, learning_rate=0.01, depth=6, verbose=0),\n",
    "    \"Neural Network\": keras.models.Sequential([\n",
    "         keras.Input(shape=(len(X.columns),)),\n",
    "         layers.BatchNormalization( momentum=0.9),\n",
    "         layers.Dense(128, activation='relu'),\n",
    "         layers.BatchNormalization(momentum=0.9),\n",
    "         layers.Dense(46, activation='tanh'),  \n",
    "         layers.BatchNormalization( momentum=0.9),\n",
    "         layers.Dense(30, activation='relu'),\n",
    "         layers.BatchNormalization(momentum=0.9),\n",
    "         layers.Dense(30, activation='relu'),\n",
    "         layers.BatchNormalization(momentum=0.9),      \n",
    "         layers.Dense(106, activation=LeakyReLU(negative_slope=0.4)),\n",
    "         layers.BatchNormalization(momentum=0.9),\n",
    "         layers.Dense(len(categories), activation='softmax')])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ... CatBoost\n",
      "Starting ... Neural Network\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[226], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0009730546622782074\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[0;32m     12\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_n\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n\u001b[0;32m     15\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\iot-poweruser\\Desktop\\Advanced_ML\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Creating a list to store the results\n",
    "results = []\n",
    "# for each model\n",
    "for name, model in models.items():\n",
    "    print(\"Starting ... \" + name)\n",
    "    model.random_state = 78\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    if name == 'Neural Network':\n",
    "        model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0009730546622782074), loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "        early_stop = keras.callbacks.EarlyStopping(patience=10, monitor='val_loss', mode='min', restore_best_weights=True)\n",
    "        model.fit(X_train_scaled, y_train_n, validation_data=(X_val_scaled, y_val_n), callbacks=[early_stop], epochs=500, batch_size=64, verbose=0)\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        y_test_n = np.argmax(y_test_n, axis=1)\n",
    "        accuracy = accuracy_score(y_test_n, predictions)\n",
    "        precision = precision_score(y_test_n, predictions, average=\"macro\")\n",
    "        recall = recall_score(y_test_n, predictions, average=\"macro\")\n",
    "        f1 = f1_score(y_test_n, predictions, average=\"macro\")\n",
    "\n",
    "    elif name in ['SVR', 'KNN', 'MLP Classifier', 'SVC']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        probability = model.predict_proba(X_test_scaled) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    elif name == 'CatBoost':\n",
    "        model.fit(X_train, y_train, cat_features=category_features, verbose=0)\n",
    "        predictions = model.predict(X_test)\n",
    "        probability = model.predict_proba(X_test)\n",
    "\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        probability = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    end = time.time()\n",
    "    Train_Time = round(end - start, 2)\n",
    "    # calculate the metrics\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    # Calculate metrics for current model in training\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions, average=\"macro\")\n",
    "    recall = recall_score(y_test, predictions, average=\"macro\")\n",
    "    f1 = f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # ROC AUC\n",
    "    if probability is not None:\n",
    "        y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
    "        roc_auc = roc_auc_score(y_test, probability, multi_class='ovr')\n",
    "    else:\n",
    "        roc_auc = np.nan\n",
    "\n",
    "    # save the metrics for this model into results\n",
    "    results.append([name, accuracy, precision, recall, f1, roc_auc, Train_Time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.827782</td>\n",
       "      <td>0.448024</td>\n",
       "      <td>0.394792</td>\n",
       "      <td>0.404003</td>\n",
       "      <td>0.741866</td>\n",
       "      <td>27.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.823372</td>\n",
       "      <td>0.436565</td>\n",
       "      <td>0.391213</td>\n",
       "      <td>0.398864</td>\n",
       "      <td>0.692915</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.834281</td>\n",
       "      <td>0.467616</td>\n",
       "      <td>0.384802</td>\n",
       "      <td>0.392739</td>\n",
       "      <td>0.767030</td>\n",
       "      <td>577.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.835616</td>\n",
       "      <td>0.474449</td>\n",
       "      <td>0.384311</td>\n",
       "      <td>0.392311</td>\n",
       "      <td>0.766610</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.835006</td>\n",
       "      <td>0.472027</td>\n",
       "      <td>0.383860</td>\n",
       "      <td>0.391635</td>\n",
       "      <td>0.767030</td>\n",
       "      <td>37.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.818992</td>\n",
       "      <td>0.429613</td>\n",
       "      <td>0.383633</td>\n",
       "      <td>0.390194</td>\n",
       "      <td>0.674954</td>\n",
       "      <td>35.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>0.830567</td>\n",
       "      <td>0.455764</td>\n",
       "      <td>0.382277</td>\n",
       "      <td>0.389118</td>\n",
       "      <td>0.727855</td>\n",
       "      <td>5.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>0.833788</td>\n",
       "      <td>0.467226</td>\n",
       "      <td>0.381413</td>\n",
       "      <td>0.388136</td>\n",
       "      <td>0.763041</td>\n",
       "      <td>45.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.834890</td>\n",
       "      <td>0.472882</td>\n",
       "      <td>0.380519</td>\n",
       "      <td>0.386996</td>\n",
       "      <td>0.756149</td>\n",
       "      <td>34.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.830858</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>0.384743</td>\n",
       "      <td>0.760411</td>\n",
       "      <td>23.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.206278</td>\n",
       "      <td>0.282926</td>\n",
       "      <td>0.299225</td>\n",
       "      <td>0.138044</td>\n",
       "      <td>0.550949</td>\n",
       "      <td>721.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall        F1  \\\n",
       "7                    XGBoost  0.827782   0.448024  0.394792  0.404003   \n",
       "5              Decision Tree  0.823372   0.436565  0.391213  0.398864   \n",
       "10            Neural Network  0.834281   0.467616  0.384802  0.392739   \n",
       "8                   LightGBM  0.835616   0.474449  0.384311  0.392311   \n",
       "9                   CatBoost  0.835006   0.472027  0.383860  0.391635   \n",
       "3                        KNN  0.818992   0.429613  0.383633  0.390194   \n",
       "6     Extra Trees Classifier  0.830567   0.455764  0.382277  0.389118   \n",
       "4             MLP Classifier  0.833788   0.467226  0.381413  0.388136   \n",
       "1   Random Forest Classifier  0.834890   0.472882  0.380519  0.386996   \n",
       "0        Logistic Regression  0.830858   0.456170  0.379100  0.384743   \n",
       "2                        SVC  0.206278   0.282926  0.299225  0.138044   \n",
       "\n",
       "     ROC AUC    Time  \n",
       "7   0.741866   27.05  \n",
       "5   0.692915    0.31  \n",
       "10  0.767030  577.28  \n",
       "8   0.766610    3.24  \n",
       "9   0.767030   37.00  \n",
       "3   0.674954   35.98  \n",
       "6   0.727855    5.49  \n",
       "4   0.763041   45.02  \n",
       "1   0.756149   34.96  \n",
       "0   0.760411   23.84  \n",
       "2   0.550949  721.73  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', \"Precision\", \"Recall\", \"F1\", \"ROC AUC\", 'Time'])\n",
    "results_df.sort_values('F1', ascending=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the results\n",
    "results_df.to_csv('dataset_classification/results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
